{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#mindyolo","title":"MindYOLO","text":"<p>MindYOLO is MindSpore Lab's software toolbox that implements state-of-the-art YOLO series algorithms, support list and benchmark. It is written in Python and powered by the MindSpore AI framework.</p> <p>The master branch supporting MindSpore 2.0.</p> <p></p>"},{"location":"#what-is-new","title":"What is New","text":"<ul> <li>2023/06/15</li> </ul> <ol> <li>Support YOLOv3/v4/v5/X/v7/v8 6 models and release 23 corresponding weights, see MODEL ZOO for details.</li> <li>Support MindSpore 2.0.</li> <li>Support deployment on MindSpore lite 2.0.</li> <li>New online documents are available!</li> </ol>"},{"location":"#benchmark-and-model-zoo","title":"Benchmark and Model Zoo","text":"<p>See MODEL ZOO.</p> Supported Algorithms <ul> <li> YOLOv8</li> <li> YOLOv7</li> <li> YOLOX</li> <li> YOLOv5</li> <li> YOLOv4</li> <li> YOLOv3</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#dependency","title":"Dependency","text":"<ul> <li>mindspore &gt;= 2.0</li> <li>numpy &gt;= 1.17.0</li> <li>pyyaml &gt;= 5.3</li> <li>openmpi 4.0.3 (for distributed mode)</li> </ul> <p>To install the dependency, please run</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>MindSpore can be easily installed by following the official instructions where you can select your hardware platform for the best fit. To run in distributed mode, openmpi is required to install.</p> <p>\u26a0\ufe0f The current version only supports the Ascend platform, and the GPU platform will be supported later.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>See GETTING STARTED</p>"},{"location":"#learn-more-about-mindyolo","title":"Learn More about MindYOLO","text":"<p>To be supplemented.</p>"},{"location":"#notes","title":"Notes","text":"<p>\u26a0\ufe0f The current version is based on the static shape of GRAPH. The dynamic shape of the PYNATIVE will be supported later. Please look forward to it.</p>"},{"location":"#how-to-contribute","title":"How to Contribute","text":"<p>We appreciate all contributions including issues and PRs to make MindYOLO better. </p> <p>Please refer to CONTRIBUTING.md for the contributing guideline.</p>"},{"location":"#license","title":"License","text":"<p>MindYOLO is released under the Apache License 2.0.</p>"},{"location":"#acknowledgement","title":"Acknowledgement","text":"<p>MindYOLO is an open source project that welcome any contribution and feedback. We wish that the toolbox and benchmark could support the growing research community, reimplement existing methods, and develop their own new real-time object detection methods by providing a flexible and standardized toolkit.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you find this project useful in your research, please consider cite:</p> <pre><code>@misc{MindSpore Object Detection YOLO 2023,\n    title={{MindSpore Object Detection YOLO}:MindSpore Object Detection YOLO Toolbox and Benchmark},\n    author={MindSpore YOLO Contributors},\n    howpublished = {\\url{https://github.com/mindspore-lab/mindyolo}},\n    year={2023}\n}\n</code></pre>"},{"location":"modelzoo/","title":"Model Zoo","text":""},{"location":"modelzoo/#mindyolo-model-zoo-and-baselines","title":"MindYOLO Model Zoo and Baselines","text":"Name Scale Context ImageSize Dataset Box mAP (%) Params FLOPs Recipe Download YOLOv8 N D910x8-G 640 MS COCO 2017 37.2 3.2M 8.7G yaml weights YOLOv8 S D910x8-G 640 MS COCO 2017 44.6 11.2M 28.6G yaml weights YOLOv8 M D910x8-G 640 MS COCO 2017 50.5 25.9M 78.9G yaml weights YOLOv8 L D910x8-G 640 MS COCO 2017 52.8 43.7M 165.2G yaml weights YOLOv8 X D910x8-G 640 MS COCO 2017 53.7 68.2M 257.8G yaml weights YOLOv7 Tiny D910x8-G 640 MS COCO 2017 37.5 6.2M 13.8G yaml weights YOLOv7 L D910x8-G 640 MS COCO 2017 50.8 36.9M 104.7G yaml weights YOLOv7 X D910x8-G 640 MS COCO 2017 52.4 71.3M 189.9G yaml weights YOLOv5 N D910x8-G 640 MS COCO 2017 27.3 1.9M 4.5G yaml weights YOLOv5 S D910x8-G 640 MS COCO 2017 37.6 7.2M 16.5G yaml weights YOLOv5 M D910x8-G 640 MS COCO 2017 44.9 21.2M 49.0G yaml weights YOLOv5 L D910x8-G 640 MS COCO 2017 48.5 46.5M 109.1G yaml weights YOLOv5 X D910x8-G 640 MS COCO 2017 50.5 86.7M 205.7G yaml weights YOLOv4 CSPDarknet53 D910x8-G 608 MS COCO 2017 45.4 27.6M 52G yaml weights YOLOv4 CSPDarknet53(silu) D910x8-G 608 MS COCO 2017 45.8 27.6M 52G yaml weights YOLOv3 Darknet53 D910x8-G 640 MS COCO 2017 45.5 61.9M 156.4G yaml weights YOLOX N D910x8-G 416 MS COCO 2017 24.1 0.9M 1.1G yaml weights YOLOX Tiny D910x8-G 416 MS COCO 2017 33.3 5.1M 6.5G yaml weights YOLOX S D910x8-G 640 MS COCO 2017 40.7 9.0M 26.8G yaml weights YOLOX M D910x8-G 640 MS COCO 2017 46.7 25.3M 73.8G yaml weights YOLOX L D910x8-G 640 MS COCO 2017 49.2 54.2M 155.6G yaml weights YOLOX X D910x8-G 640 MS COCO 2017 51.6 99.1M 281.9G yaml weights YOLOX Darknet53 D910x8-G 640 MS COCO 2017 47.7 63.7M 185.3G yaml weights"},{"location":"modelzoo/#depoly-inference","title":"Depoly inference","text":"<ul> <li>See support list</li> </ul>"},{"location":"modelzoo/#notes","title":"Notes","text":"<ul> <li>Context: Training context denoted as {device}x{pieces}-{MS mode}, where mindspore mode can be G - graph mode or F - pynative mode with ms function. For example, D910x8-G is for training on 8 pieces of Ascend 910 NPU using graph mode.</li> <li>Box mAP: Accuracy reported on the validation set.</li> </ul>"},{"location":"how_to_guides/write_a_new_model/","title":"Write A New Model","text":"<p>comming soon.</p>"},{"location":"notes/changelog/","title":"Change Log","text":"<p>Coming soon.</p>"},{"location":"notes/code_of_conduct/","title":"Code of Conduct","text":"<p>Coming soon.</p>"},{"location":"notes/contributing/","title":"Contributing","text":""},{"location":"notes/contributing/#mindyolo-contributing-guidelines","title":"MindYOLO contributing guidelines","text":"<ul> <li>MindYOLO contributing guidelines<ul> <li>Contributor License Agreement</li> <li>Getting Started</li> <li>Contribution workflow<ul> <li>Code style</li> <li>Fork-Pull development model</li> <li>Report issues</li> <li>Propose PRs</li> </ul> </li> </ul> </li> </ul>"},{"location":"notes/contributing/#contributor-license-agreement","title":"Contributor License Agreement","text":"<p>It's required to sign CLA before your first code submission to MindYOLO community.</p> <p>For individual contributor, please refer to ICLA online document for the detailed information.</p>"},{"location":"notes/contributing/#getting-started","title":"Getting Started","text":"<ul> <li>Fork the repository on Github.</li> <li>Read the README.md.</li> </ul>"},{"location":"notes/contributing/#contribution-workflow","title":"Contribution Workflow","text":""},{"location":"notes/contributing/#code-style","title":"Code style","text":"<p>Please follow this style to make MindYOLO easy to review, maintain and develop.</p> <ul> <li> <p>Coding guidelines</p> <p>The Python coding style suggested by Python PEP 8 Coding Style and C++ coding style suggested by Google C++ Coding Guidelines are used in MindYOLO community. The CppLint, CppCheck, CMakeLint, CodeSpell, Lizard, ShellCheck and PyLint are used to check the format of codes, installing these plugins in your IDE is recommended.</p> </li> <li> <p>Unittest guidelines</p> <p>The Python unittest style suggested by pytest and C++ unittest style suggested by Googletest Primer are used in MindYOLO community. The design intent of a testcase should be reflected by its name of comment.</p> </li> <li> <p>Refactoring guidelines</p> <p>We encourage developers to refactor our code to eliminate the code smell. All codes should conform to needs to the coding style and testing style, and refactoring codes are no exception. Lizard threshold for nloc (lines of code without comments) is 100 and for cnc (cyclomatic complexity number) is 20, when you receive a Lizard warning, you have to refactor the code you want to merge.</p> </li> <li> <p>Document guidelines</p> <p>We use MarkdownLint to check the format of markdown documents. MindYOLO CI modifies the following rules based on the default configuration. - MD007 (unordered list indentation): The indent parameter is set to 4, indicating that all content in the unordered list needs to be indented using four spaces. - MD009 (spaces at the line end): The br_spaces parameter is set to 2, indicating that there can be 0 or 2 spaces at the end of a line. - MD029 (sequence numbers of an ordered list): The style parameter is set to ordered, indicating that the sequence numbers of the ordered list are in ascending order.</p> <p>For details, please refer to RULES.</p> </li> </ul>"},{"location":"notes/contributing/#fork-pull-development-model","title":"Fork-Pull development model","text":"<ul> <li> <p>Fork MindYOLO repository</p> <p>Before submitting code to MindYOLO project, please make sure that this project have been forked to your own repository. It means that there will be parallel development between MindYOLO repository and your own repository, so be careful to avoid the inconsistency between them.</p> </li> <li> <p>Clone the remote repository</p> <p>If you want to download the code to the local machine, <code>git</code> is the best way:</p> <pre><code># For GitHub\ngit clone https://github.com/{insert_your_forked_repo}/mindyolo.git\ngit remote add upstream https://github.com/mindspore-lab/mindyolo.git\n</code></pre> </li> <li> <p>Develop code locally</p> <p>To avoid inconsistency between multiple branches, checking out to a new branch is <code>SUGGESTED</code>:</p> <pre><code>git checkout -b {new_branch_name} origin/master\n</code></pre> <p>Taking the master branch as an example, MindYOLO may create version branches and downstream development branches as needed, please fix bugs upstream first. Then you can change the code arbitrarily.</p> </li> <li> <p>Push the code to the remote repository</p> <p>After updating the code, you should push the update in the formal way:</p> <pre><code>git add .\ngit status # Check the update status\ngit commit -m \"Your commit title\"\ngit commit -s --amend #Add the concrete description of your commit\ngit push origin {new_branch_name}\n</code></pre> </li> <li> <p>Pull a request to MindYOLO repository</p> <p>In the last step, your need to pull a compare request between your new branch and MindYOLO <code>master</code> branch. After finishing the pull request, the Jenkins CI will be automatically set up for building test. Your pull request should be merged into the upstream master branch as soon as possible to reduce the risk of merging.</p> </li> </ul>"},{"location":"notes/contributing/#report-issues","title":"Report issues","text":"<p>A great way to contribute to the project is to send a detailed report when you encounter an issue. We always appreciate a well-written, thorough bug report, and will thank you for it!</p> <p>When reporting issues, refer to this format:</p> <ul> <li>What version of env (MindSpore, os, python, MindYOLO etc) are you using?</li> <li>Is this a BUG REPORT or FEATURE REQUEST?</li> <li>What kind of issue is, add the labels to highlight it on the issue dashboard.</li> <li>What happened?</li> <li>What you expected to happen?</li> <li>How to reproduce it?(as minimally and precisely as possible)</li> <li>Special notes for your reviewers?</li> </ul> <p>Issues advisory:</p> <ul> <li>If you find an unclosed issue, which is exactly what you are going to solve, please put some comments on that issue to tell others you would be in charge of it.</li> <li>If an issue is opened for a while, it's recommended for contributors to precheck before working on solving that issue.</li> <li>If you resolve an issue which is reported by yourself, it's also required to let others know before closing that issue.</li> <li>If you want the issue to be responded as quickly as possible, please try to label it, you can find kinds of labels on Label List</li> </ul>"},{"location":"notes/contributing/#propose-prs","title":"Propose PRs","text":"<ul> <li>Raise your idea as an issue on GitHub </li> <li>If it is a new feature that needs lots of design details, a design proposal should also be submitted.</li> <li>After reaching consensus in the issue discussions and design proposal reviews, complete the development on the forked repo and submit a PR.</li> <li>None of PRs is not permitted until it receives 2+ LGTM from approvers. Please NOTICE that approver is NOT allowed to add LGTM on his own PR.</li> <li>After PR is sufficiently discussed, it will get merged, abandoned or rejected depending on the outcome of the discussion.</li> </ul> <p>PRs advisory:</p> <ul> <li>Any irrelevant changes should be avoided.</li> <li>Make sure your commit history being ordered.</li> <li>Always keep your branch up with the master branch.</li> <li>For bug-fix PRs, make sure all related issues being linked.</li> </ul>"},{"location":"notes/faq/","title":"FAQ","text":"<p>Coming soon.</p>"},{"location":"reference/data/","title":"Data","text":""},{"location":"reference/data/#comming-soon","title":"comming soon","text":""},{"location":"reference/loss/","title":"Loss","text":""},{"location":"reference/loss/#loss-factory","title":"Loss Factory","text":""},{"location":"reference/models/","title":"Models","text":""},{"location":"reference/models/#create-model","title":"Create Model","text":""},{"location":"reference/models/#mindyolo.models.model_factory.create_model","title":"<code>mindyolo.models.model_factory.create_model(model_name, model_cfg=None, in_channels=3, num_classes=80, checkpoint_path='', **kwargs)</code>","text":"Source code in <code>mindyolo/models/model_factory.py</code> <pre><code>def create_model(\n    model_name: str,\n    model_cfg: dict = None,\n    in_channels: int = 3,\n    num_classes: int = 80,\n    checkpoint_path: str = \"\",\n    **kwargs,\n):\n    model_args = dict(cfg=model_cfg, num_classes=num_classes, in_channels=in_channels)\n    kwargs = {k: v for k, v in kwargs.items() if v is not None}\n\n    if not is_model(model_name):\n        raise RuntimeError(f\"Unknown model {model_name}\")\n\n    create_fn = model_entrypoint(model_name)\n    model = create_fn(**model_args, **kwargs)\n\n    if checkpoint_path:\n        assert os.path.isfile(checkpoint_path) and checkpoint_path.endswith(\n            \".ckpt\"\n        ), f\"[{checkpoint_path}] not a ckpt file.\"\n        checkpoint_param = load_checkpoint(checkpoint_path)\n        load_param_into_net(model, checkpoint_param)\n        logger.info(f\"Load checkpoint from [{checkpoint_path}] success.\")\n\n    return model\n</code></pre>"},{"location":"reference/models/#yolov3_head","title":"yolov3_head","text":""},{"location":"reference/models/#yolov4_head","title":"yolov4_head","text":""},{"location":"reference/models/#yolov5_head","title":"yolov5_head","text":""},{"location":"reference/models/#yolov7_head","title":"yolov7_head","text":""},{"location":"reference/models/#yolov8_head","title":"yolov8_head","text":""},{"location":"reference/models/#yolox_head","title":"yolox_head","text":""},{"location":"reference/models/#initializer","title":"initializer","text":""},{"location":"reference/models/#focal_loss","title":"focal_loss","text":""},{"location":"reference/models/#iou_loss","title":"iou_loss","text":""},{"location":"reference/models/#label_assignment","title":"label_assignment","text":""},{"location":"reference/models/#loss_factory","title":"loss_factory","text":""},{"location":"reference/models/#yolov3_loss","title":"yolov3_loss","text":""},{"location":"reference/models/#yolov4_loss","title":"yolov4_loss","text":""},{"location":"reference/models/#yolov5_loss","title":"yolov5_loss","text":""},{"location":"reference/models/#yolov7_loss","title":"yolov7_loss","text":""},{"location":"reference/models/#yolov8_loss","title":"yolov8_loss","text":""},{"location":"reference/models/#yolox_loss","title":"yolox_loss","text":""},{"location":"reference/models/#yolov3","title":"yolov3","text":""},{"location":"reference/models/#yolov4","title":"yolov4","text":""},{"location":"reference/models/#yolov5","title":"yolov5","text":""},{"location":"reference/models/#yolov7","title":"yolov7","text":""},{"location":"reference/models/#yolov8","title":"yolov8","text":""},{"location":"reference/models/#yolox","title":"yolox","text":""},{"location":"tutorials/configuration/","title":"Configuration","text":""},{"location":"tutorials/configuration/#_1","title":"\u914d\u7f6e","text":"<p>MindYOLO\u5957\u4ef6\u540c\u65f6\u652f\u6301yaml\u6587\u4ef6\u53c2\u6570\u548c\u547d\u4ee4\u884c\u53c2\u6570\u89e3\u6790\uff0c\u5e76\u5c06\u76f8\u5bf9\u56fa\u5b9a\u3001\u4e0e\u6a21\u578b\u5f3a\u76f8\u5173\u3001\u8f83\u4e3a\u590d\u6742\u6216\u8005\u542b\u6709\u5d4c\u5957\u7ed3\u6784\u7684\u53c2\u6570\u7f16\u5199\u6210yaml\u6587\u4ef6\uff0c\u9700\u6839\u636e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u66f4\u6539\u6216\u8005\u8f83\u4e3a\u7b80\u5355\u7684\u53c2\u6570\u5219\u901a\u8fc7\u547d\u4ee4\u884c\u4f20\u5165\u3002</p> <p>\u4e0b\u9762\u4ee5yolov3\u4e3a\u4f8b\uff0c\u89e3\u91ca\u5982\u4f55\u914d\u7f6e\u76f8\u5e94\u7684\u53c2\u6570\u3002</p>"},{"location":"tutorials/configuration/#_2","title":"\u53c2\u6570\u7ee7\u627f\u5173\u7cfb","text":"<p>\u53c2\u6570\u4f18\u5148\u7ea7\u7531\u9ad8\u5230\u4f4e\u5982\u4e0b\uff0c\u51fa\u73b0\u540c\u540d\u53c2\u6570\u65f6\uff0c\u4f4e\u4f18\u5148\u7ea7\u53c2\u6570\u4f1a\u88ab\u9ad8\u4f18\u5148\u7ea7\u53c2\u6570\u8986\u76d6</p> <ul> <li>\u7528\u6237\u547d\u4ee4\u884c\u4f20\u5165\u53c2\u6570</li> <li>python\u6267\u884cpy\u6587\u4ef6\u4e2dparser\u7684\u9ed8\u8ba4\u53c2\u6570</li> <li>\u547d\u4ee4\u884c\u4f20\u5165config\u53c2\u6570\u5bf9\u5e94\u7684yaml\u6587\u4ef6\u53c2\u6570</li> <li>\u547d\u4ee4\u884c\u4f20\u5165config\u53c2\u6570\u5bf9\u5e94\u7684yaml\u6587\u4ef6\u4e2d__BASE__\u53c2\u6570\u4e2d\u5305\u542b\u7684yaml\u6587\u4ef6\u53c2\u6570\uff0c\u4f8b\u5982yolov3.yaml\u542b\u6709\u5982\u4e0b\u53c2\u6570\uff1a <pre><code>__BASE__: [\n'../coco.yaml',\n'./hyp.scratch.yaml',\n]\n</code></pre></li> </ul>"},{"location":"tutorials/configuration/#_3","title":"\u57fa\u7840\u53c2\u6570","text":""},{"location":"tutorials/configuration/#_4","title":"\u53c2\u6570\u8bf4\u660e","text":"<ul> <li>device_target: \u6240\u7528\u8bbe\u5907\uff0cAscend/GPU/CPU</li> <li>save_dir: \u8fd0\u884c\u7ed3\u679c\u4fdd\u5b58\u8def\u5f84\uff0c\u9ed8\u8ba4\u4e3a./runs</li> <li>log_interval: \u6253\u5370\u65e5\u5fd7step\u95f4\u9694\uff0c\u9ed8\u8ba4\u4e3a100</li> <li>is_parallel: \u662f\u5426\u5206\u5e03\u5f0f\u8bad\u7ec3\uff0c\u9ed8\u8ba4\u4e3aFalse</li> <li>ms_mode: \u4f7f\u7528\u9759\u6001\u56fe\u6a21\u5f0f(0)\u6216\u52a8\u6001\u56fe\u6a21\u5f0f(1)\uff0c\u9ed8\u8ba4\u4e3a0\u3002</li> <li>config: yaml\u914d\u7f6e\u6587\u4ef6\u8def\u5f84</li> <li>per_batch_size: \u6bcf\u5f20\u5361batch size\uff0c\u9ed8\u8ba4\u4e3a32</li> <li>epochs: \u8bad\u7ec3epoch\u6570\uff0c\u9ed8\u8ba4\u4e3a300</li> <li>...</li> </ul>"},{"location":"tutorials/configuration/#parse","title":"parse\u53c2\u6570\u8bbe\u7f6e","text":"<p>\u8be5\u90e8\u5206\u53c2\u6570\u901a\u5e38\u7531\u547d\u4ee4\u884c\u4f20\u5165\uff0c\u793a\u4f8b\u5982\u4e0b\uff1a</p> <pre><code>mpirun --allow-run-as-root -n 8 python train.py --config ./configs/yolov7/yolov7.yaml  --is_parallel True --log_interval 50\n</code></pre>"},{"location":"tutorials/configuration/#_5","title":"\u6570\u636e\u96c6","text":""},{"location":"tutorials/configuration/#_6","title":"\u53c2\u6570\u8bf4\u660e","text":"<ul> <li>dataset_name: \u6570\u636e\u96c6\u540d\u79f0</li> <li>train_set: \u8bad\u7ec3\u96c6\u6240\u5728\u8def\u5f84</li> <li>val_set: \u9a8c\u8bc1\u96c6\u6240\u5728\u8def\u5f84</li> <li>test_set: \u6d4b\u8bd5\u96c6\u6240\u5728\u8def\u5f84</li> <li>nc: \u6570\u636e\u96c6\u7c7b\u522b\u6570</li> <li>names: \u7c7b\u522b\u540d\u79f0</li> <li>...</li> </ul>"},{"location":"tutorials/configuration/#yaml","title":"yaml\u6587\u4ef6\u6837\u4f8b","text":"<p>\u8be5\u90e8\u5206\u53c2\u6570\u5728configs/coco.yaml\u4e2d\u5b9a\u4e49\uff0c\u901a\u5e38\u9700\u4fee\u6539\u5176\u4e2d\u7684\u6570\u636e\u96c6\u8def\u5f84</p> <p>```yaml data:   dataset_name: coco</p> <p>train_set: ./coco/train2017.txt  # 118287 images   val_set: ./coco/val2017.txt  # 5000 images   test_set: ./coco/test-dev2017.txt  # 20288 of 40670 images, submit to https://competitions.codalab.org/competitions/20794</p> <p>nc: 80</p> <p># class names   names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',            'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',            'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',            'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',            'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',            'hair drier', 'toothbrush' ]  ```</p>"},{"location":"tutorials/configuration/#_7","title":"\u6570\u636e\u589e\u5f3a","text":""},{"location":"tutorials/configuration/#_8","title":"\u53c2\u6570\u8bf4\u660e","text":"<ul> <li>num_parallel_workers: \u8bfb\u53d6\u6570\u636e\u7684\u5de5\u4f5c\u8fdb\u7a0b\u6570</li> <li>train_transformers: \u8bad\u7ec3\u8fc7\u7a0b\u6570\u636e\u589e\u5f3a</li> <li>test_transformers: \u9a8c\u8bc1\u8fc7\u7a0b\u6570\u636e\u589e\u5f3a</li> <li>...</li> </ul>"},{"location":"tutorials/configuration/#yaml_1","title":"yaml\u6587\u4ef6\u6837\u4f8b","text":"<p>\u8be5\u90e8\u5206\u53c2\u6570\u5728configs/yolov3/hyp.scratch.yaml\u4e2d\u5b9a\u4e49\uff0c\u5176\u4e2dtrain_transformers\u548ctest_transformers\u5747\u4e3a\u7531\u5b57\u5178\u7ec4\u6210\u7684\u5217\u8868\uff0c\u5404\u5b57\u5178\u5305\u542b\u6570\u636e\u589e\u5f3a\u64cd\u4f5c\u540d\u79f0\u3001\u53d1\u751f\u6982\u7387\u53ca\u8be5\u589e\u5f3a\u65b9\u6cd5\u76f8\u5173\u7684\u53c2\u6570</p> <p>```yaml data:   num_parallel_workers: 4</p> <p>train_transforms:     - { func_name: mosaic, prob: 1.0, mosaic9_prob: 0.0, translate: 0.1, scale: 0.9 }     - { func_name: mixup, prob: 0.1, alpha: 8.0, beta: 8.0, needed_mosaic: True }     - { func_name: hsv_augment, prob: 1.0, hgain: 0.015, sgain: 0.7, vgain: 0.4 }     - { func_name: label_norm, xyxy2xywh_: True }     - { func_name: albumentations }     - { func_name: fliplr, prob: 0.5 }     - { func_name: label_pad, padding_size: 160, padding_value: -1 }     - { func_name: image_norm, scale: 255. }     - { func_name: image_transpose, bgr2rgb: True, hwc2chw: True }</p> <p>test_transforms:     - { func_name: letterbox, scaleup: False }     - { func_name: label_norm, xyxy2xywh_: True }     - { func_name: label_pad, padding_size: 160, padding_value: -1 }     - { func_name: image_norm, scale: 255. }     - { func_name: image_transpose, bgr2rgb: True, hwc2chw: True }   ```</p>"},{"location":"tutorials/configuration/#_9","title":"\u6a21\u578b","text":""},{"location":"tutorials/configuration/#_10","title":"\u53c2\u6570\u8bf4\u660e","text":"<ul> <li>model_name: \u6a21\u578b\u540d\u79f0</li> <li>depth_multiple: \u6a21\u578b\u6df1\u5ea6\u56e0\u5b50</li> <li>width_multiple: \u6a21\u578b\u5bbd\u5ea6\u56e0\u5b50</li> <li>stride: \u7279\u5f81\u56fe\u4e0b\u91c7\u6837\u500d\u6570</li> <li>anchors: \u9884\u8bbe\u951a\u6846</li> <li>backbone: \u6a21\u578b\u9aa8\u5e72\u7f51\u7edc</li> <li>head: \u6a21\u578b\u68c0\u6d4b\u5934</li> </ul>"},{"location":"tutorials/configuration/#yaml_2","title":"yaml\u6587\u4ef6\u6837\u4f8b","text":"<p>\u8be5\u90e8\u5206\u53c2\u6570\u5728configs/yolov3/yolov3.yaml\u4e2d\u5b9a\u4e49\uff0c\u6839\u636ebackbon\u548chead\u53c2\u6570\u8fdb\u884c\u7f51\u7edc\u6784\u5efa\uff0c\u53c2\u6570\u4ee5\u5d4c\u5957\u5217\u8868\u7684\u5f62\u5f0f\u5448\u73b0\uff0c\u6bcf\u884c\u4ee3\u8868\u4e00\u5c42\u6a21\u5757\uff0c\u5305\u542b4\u4e2a\u53c2\u6570\uff0c\u5206\u522b\u662f \u8f93\u5165\u5c42\u7f16\u53f7(-1\u4ee3\u8868\u4e0a\u4e00\u5c42)\u3001\u6a21\u5757\u91cd\u590d\u6b21\u6570\u3001\u6a21\u5757\u540d\u79f0\u548c\u6a21\u5757\u76f8\u5e94\u53c2\u6570\u3002\u7528\u6237\u4e5f\u53ef\u4ee5\u4e0d\u501f\u52a9yaml\u6587\u4ef6\u800c\u76f4\u63a5\u5728py\u6587\u4ef6\u4e2d\u5b9a\u4e49\u548c\u6ce8\u518c\u7f51\u7edc\u3002 ```yaml network:   model_name: yolov3</p> <p>depth_multiple: 1.0  # model depth multiple   width_multiple: 1.0  # layer channel multiple   stride: [8, 16, 32]   anchors:     - [10,13, 16,30, 33,23]  # P\u215c     - [30,61, 62,45, 59,119]  # P4/16     - [116,90, 156,198, 373,326]  # P5/32</p> <p># darknet53 backbone   backbone:     # [from, number, module, args]     [[-1, 1, ConvNormAct, [32, 3, 1]],  # 0      [-1, 1, ConvNormAct, [64, 3, 2]],  # 1-P\u00bd      [-1, 1, Bottleneck, [64]],      [-1, 1, ConvNormAct, [128, 3, 2]],  # 3-P2/4      [-1, 2, Bottleneck, [128]],      [-1, 1, ConvNormAct, [256, 3, 2]],  # 5-P\u215c      [-1, 8, Bottleneck, [256]],      [-1, 1, ConvNormAct, [512, 3, 2]],  # 7-P4/16      [-1, 8, Bottleneck, [512]],      [-1, 1, ConvNormAct, [1024, 3, 2]],  # 9-P5/32      [-1, 4, Bottleneck, [1024]],  # 10     ]</p> <p># YOLOv3 head   head:     [[-1, 1, Bottleneck, [1024, False]],      [-1, 1, ConvNormAct, [512, 1, 1]],      [-1, 1, ConvNormAct, [1024, 3, 1]],      [-1, 1, ConvNormAct, [512, 1, 1]],      [-1, 1, ConvNormAct, [1024, 3, 1]],  # 15 (P5/32-large)</p> <pre><code> [-2, 1, ConvNormAct, [256, 1, 1]],\n [-1, 1, Upsample, [None, 2, 'nearest']],\n [[-1, 8], 1, Concat, [1]],  # cat backbone P4\n [-1, 1, Bottleneck, [512, False]],\n [-1, 1, Bottleneck, [512, False]],\n [-1, 1, ConvNormAct, [256, 1, 1]],\n [-1, 1, ConvNormAct, [512, 3, 1]],  # 22 (P4/16-medium)\n\n [-2, 1, ConvNormAct, [128, 1, 1]],\n [-1, 1, Upsample, [None, 2, 'nearest']],\n [[-1, 6], 1, Concat, [1]],  # cat backbone P3\n [-1, 1, Bottleneck, [256, False]],\n [-1, 2, Bottleneck, [256, False]],  # 27 (P3/8-small)\n\n [[27, 22, 15], 1, YOLOv3Head, [nc, anchors, stride]],   # Detect(P3, P4, P5)\n]\n</code></pre> <p>```</p>"},{"location":"tutorials/configuration/#_11","title":"\u635f\u5931\u51fd\u6570","text":""},{"location":"tutorials/configuration/#_12","title":"\u53c2\u6570\u8bf4\u660e","text":"<ul> <li>name: \u635f\u5931\u51fd\u6570\u540d\u79f0</li> <li>box: box\u635f\u5931\u6743\u91cd</li> <li>cls: class\u635f\u5931\u6743\u91cd</li> <li>cls_pw: class\u635f\u5931\u6b63\u6837\u672c\u6743\u91cd</li> <li>obj: object\u635f\u5931\u6743\u91cd</li> <li>obj_pw: object\u635f\u5931\u6b63\u6837\u672c\u6743\u91cd</li> <li>fl_gamma: focal loss gamma</li> <li>anchor_t: anchor shape\u6bd4\u4f8b\u9608\u503c</li> <li>label_smoothing: \u6807\u7b7e\u5e73\u6ed1\u503c</li> </ul>"},{"location":"tutorials/configuration/#yaml_3","title":"yaml\u6587\u4ef6\u6837\u4f8b","text":"<p>\u8be5\u90e8\u5206\u53c2\u6570\u5728configs/yolov3/hyp.scratch.yaml\u4e2d\u5b9a\u4e49</p> <p><code>yaml loss:   name: YOLOv7Loss   box: 0.05  # box loss gain   cls: 0.5  # cls loss gain   cls_pw: 1.0  # cls BCELoss positive_weight   obj: 1.0  # obj loss gain (scale with pixels)   obj_pw: 1.0  # obj BCELoss positive_weight   fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)   anchor_t: 4.0  # anchor-multiple threshold   label_smoothing: 0.0 # label smoothing epsilon</code></p>"},{"location":"tutorials/configuration/#_13","title":"\u4f18\u5316\u5668","text":""},{"location":"tutorials/configuration/#_14","title":"\u53c2\u6570\u8bf4\u660e","text":"<ul> <li>optimizer: \u4f18\u5316\u5668\u540d\u79f0\u3002</li> <li>lr_init: \u5b66\u4e60\u7387\u521d\u59cb\u503c</li> <li>warmup_epochs: warmup epoch\u6570</li> <li>warmup_momentum: warmup momentum\u521d\u59cb\u503c</li> <li>warmup_bias_lr: warmup bias\u5b66\u4e60\u7387\u521d\u59cb\u503c</li> <li>min_warmup_step: \u6700\u5c0fwarmup step\u6570</li> <li>group_param: \u53c2\u6570\u5206\u7ec4\u7b56\u7565</li> <li>gp_weight_decay: \u5206\u7ec4\u53c2\u6570\u6743\u91cd\u8870\u51cf\u7cfb\u6570</li> <li>start_factor: \u521d\u59cb\u5b66\u4e60\u7387\u56e0\u6570</li> <li>end_factor: \u7ed3\u675f\u5b66\u4e60\u7387\u56e0\u6570</li> <li>momentum\uff1a\u79fb\u52a8\u5e73\u5747\u7684\u52a8\u91cf</li> <li>loss_scale\uff1aloss\u7f29\u653e\u7cfb\u6570</li> <li>nesterov\uff1a\u662f\u5426\u4f7f\u7528Nesterov Accelerated Gradient (NAG)\u7b97\u6cd5\u66f4\u65b0\u68af\u5ea6\u3002</li> </ul>"},{"location":"tutorials/configuration/#yaml_4","title":"yaml\u6587\u4ef6\u6837\u4f8b","text":"<p>\u8be5\u90e8\u5206\u53c2\u6570\u5728configs/yolov3/hyp.scratch.yaml\u4e2d\u5b9a\u4e49\uff0c\u5982\u4e0b\u793a\u4f8b\u4e2d\u7ecf\u8fc7warmup\u9636\u6bb5\u540e\u7684\u521d\u59cb\u5b66\u4e60\u7387\u4e3alr_init * start_factor = 0.01 * 1.0 = 0.01, \u6700\u7ec8\u5b66\u4e60\u7387\u4e3alr_init * end_factor = 0.01 * 0.01 = 0.0001</p> <p><code>yaml optimizer:   optimizer: momentum   lr_init: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)   momentum: 0.937  # SGD momentum/Adam beta1   nesterov: True # update gradients with NAG(Nesterov Accelerated Gradient) algorithm   loss_scale: 1.0 # loss scale for optimizer   warmup_epochs: 3  # warmup epochs (fractions ok)   warmup_momentum: 0.8  # warmup initial momentum   warmup_bias_lr: 0.1  # warmup initial bias lr   min_warmup_step: 1000 # minimum warmup step   group_param: yolov7 # group param strategy   gp_weight_decay: 0.0005  # group param weight decay 5e-4   start_factor: 1.0   end_factor: 0.01</code></p>"},{"location":"tutorials/data_augmentation/","title":"Augmentation","text":""},{"location":"tutorials/data_augmentation/#-","title":"\u6570\u636e\u589e\u5f3a--\u5de5\u5177\u7bb1\u81ea\u5e26","text":"<ul> <li>\u4ee5configs/yolov7/hyp.scratch.tiny.yaml\u4e2d\u7684data.train_transforms\u4e3a\u4f8b.  \u5b83\u6307\u5b9a\u4e86\u4e00\u7ec4\u5e94\u7528\u4e8e\u56fe\u50cf\u6216\u6807\u7b7e\u7684\u6570\u636e\u589e\u5f3a\u64cd\u4f5c\uff0c\u7528\u4ee5\u751f\u6210\u4f5c\u4e3a\u6a21\u578b\u8f93\u5165\u6216\u635f\u5931\u51fd\u6570\u8f93\u5165\u7684\u6570\u636e\u3002\u8fd9\u4e9b\u6570\u636e\u589e\u5f3a\u51fd\u6570\u5b9a\u4e49\u5728 mindyolo/data/dataset.py \u4e2d\u3002 <pre><code>  train_transforms:\n- {func_name: mosaic, prob: 1.0, mosaic9_prob: 0.2, translate: 0.1, scale: 0.5}\n- {func_name: mixup, prob: 0.05, alpha: 8.0, beta: 8.0, needed_mosaic: True}\n- {func_name: hsv_augment, prob: 1.0, hgain: 0.015, sgain: 0.7, vgain: 0.4}\n- {func_name: pastein, prob: 0.05, num_sample: 30}\n- {func_name: label_norm, xyxy2xywh_: True}\n- {func_name: fliplr, prob: 0.5}\n- {func_name: label_pad, padding_size: 160, padding_value: -1}\n- {func_name: image_norm, scale: 255.}\n- {func_name: image_transpose, bgr2rgb: True, hwc2chw: True}\n</code></pre> \u6ce8\u610f\uff1afunc_name\u8868\u793a\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u540d\uff0cprob\u8868\u793a\u8be5\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u7684\u6267\u884c\u6982\u7387\uff0c\u9ed8\u8ba4\u503c\u4e3a1</li> </ul> <p>\u4e0a\u8ff0yaml\u6587\u4ef6\u6267\u884c\u7684\u5177\u4f53\u64cd\u4f5c\u5982\u4e0b\uff1a</p> <ul> <li> <p><code>mosaic</code>\uff1a\u4ee51.0\u7684\u6982\u7387\u5bf9\u8f93\u5165\u7684\u56fe\u7247\u8fdb\u884cmosaic\u64cd\u4f5c\uff0c\u5373\u5c064\u5f20\u4e0d\u540c\u7684\u56fe\u7247\u62fc\u63a5\u6210\u4e00\u5f20\u56fe\u7247\u3002mosaic9_prob\u8868\u793a\u4f7f\u75289\u5bab\u683c\u65b9\u5f0f\u8fdb\u884c\u62fc\u63a5\u7684\u6982\u7387\uff0ctranslate\u548cscale\u5206\u522b\u8868\u793a\u968f\u673a\u5e73\u79fb\u548c\u7f29\u653e\u7684\u7a0b\u5ea6\u3002</p> </li> <li> <p><code>mixup</code>\uff1a\u4ee50.05\u7684\u6982\u7387\u5bf9\u8f93\u5165\u7684\u56fe\u7247\u8fdb\u884cmixup\u64cd\u4f5c\uff0c\u5373\u5c06\u4e24\u5f20\u4e0d\u540c\u7684\u56fe\u7247\u8fdb\u884c\u6df7\u5408\u3002\u5176\u4e2dalpha\u548cbeta\u8868\u793a\u6df7\u5408\u7cfb\u6570\uff0cneeded_mosaic\u8868\u793a\u662f\u5426\u9700\u8981\u4f7f\u7528mosaic\u8fdb\u884c\u6df7\u5408\u3002</p> </li> <li> <p><code>hsv_augment</code>: HSV\u589e\u5f3a, \u4ee51.0\u7684\u6982\u7387\u5bf9\u8f93\u5165\u7684\u56fe\u7247\u8fdb\u884cHSV\u989c\u8272\u7a7a\u95f4\u7684\u8c03\u6574\uff0c\u589e\u52a0\u6570\u636e\u591a\u6837\u6027\u3002\u5176\u4e2dhgain\u3001sgain\u548cvgain\u5206\u522b\u8868\u793a\u5bf9H\u3001S\u3001V\u901a\u9053\u7684\u8c03\u6574\u7a0b\u5ea6\u3002</p> </li> <li> <p><code>pastein</code>\uff1a\u4ee50.05\u7684\u6982\u7387\u5728\u8f93\u5165\u7684\u56fe\u7247\u4e2d\u968f\u673a\u8d34\u5165\u4e00\u4e9b\u6837\u672c\u3002\u5176\u4e2dnum_sample\u8868\u793a\u968f\u673a\u8d34\u5165\u7684\u6837\u672c\u6570\u91cf\u3002</p> </li> <li> <p><code>label_norm</code>\uff1a\u5c06\u8f93\u5165\u7684\u6807\u7b7e\u4ece(x1, y1, x2, y2)\u7684\u683c\u5f0f\u8f6c\u6362\u4e3a(x, y, w, h)\u7684\u683c\u5f0f\u3002</p> </li> <li> <p><code>fliplr</code>\uff1a\u4ee50.5\u7684\u6982\u7387\u5bf9\u8f93\u5165\u7684\u56fe\u7247\u8fdb\u884c\u6c34\u5e73\u7ffb\u8f6c\uff0c\u589e\u52a0\u6570\u636e\u591a\u6837\u6027\u3002</p> </li> <li> <p><code>label_pad</code>\uff1a\u5bf9\u8f93\u5165\u7684\u6807\u7b7e\u8fdb\u884c\u586b\u5145\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u56fe\u7247\u90fd\u6709\u76f8\u540c\u6570\u91cf\u7684\u6807\u7b7e\u3002padding_size\u8868\u793a\u586b\u5145\u540e\u6807\u7b7e\u7684\u6570\u91cf\uff0cpadding_value\u8868\u793a\u586b\u5145\u7684\u503c\u3002</p> </li> <li> <p><code>image_norm</code>\uff1a\u5c06\u8f93\u5165\u7684\u56fe\u7247\u50cf\u7d20\u503c\u4ece[0, 255]\u8303\u56f4\u5185\u7f29\u653e\u5230[0, 1]\u8303\u56f4\u5185\u3002</p> </li> <li> <p><code>image_transpose</code>\uff1a\u5c06\u8f93\u5165\u7684\u56fe\u7247\u4eceBGR\u683c\u5f0f\u8f6c\u6362\u4e3aRGB\u683c\u5f0f\uff0c\u5e76\u5c06\u56fe\u7247\u7684\u901a\u9053\u6570\u4eceHWC\u683c\u5f0f\u8f6c\u6362\u4e3aCHW\u683c\u5f0f\u3002</p> </li> </ul> <p>\u5bf9\u4e8e\u6d4b\u8bd5\u6570\u636e\u589e\u5f3a\u51fd\u6570</p> <p><pre><code>  test_transforms:\n- {func_name: letterbox, scaleup: False}\n- {func_name: label_norm, xyxy2xywh_: True}\n- {func_name: label_pad, padding_size: 160, padding_value: -1}\n- {func_name: image_norm, scale: 255. }\n- {func_name: image_transpose, bgr2rgb: True, hwc2chw: True }\n</code></pre> - <code>letterbox</code>:\u5c06\u56fe\u7247\u6309\u7167\u7b49\u6bd4\u4f8b\u7f29\u653e\u540e\uff0c\u7528\u56fa\u5b9a\u7684\u80cc\u666f\u8272\u586b\u5145\u5230\u6307\u5b9a\u5927\u5c0f\u3002\u5176\u4e2dscaleup\u8868\u793a\u662f\u5426\u5141\u8bb8\u5c06\u56fe\u7247\u653e\u5927\uff0c\u4ee5\u9002\u5e94\u6307\u5b9a\u7684\u5927\u5c0f\u3002</p> <ul> <li> <p><code>label_norm</code>:\u6807\u7b7e\u5f52\u4e00\u5316,\u5c06\u8f93\u5165\u7684\u6807\u7b7e\u4ece(x1, y1, x2, y2)\u7684\u683c\u5f0f\u8f6c\u6362\u4e3a(x, y, w, h)\u7684\u683c\u5f0f\u3002</p> </li> <li> <p><code>label_pad</code>:\u6807\u7b7e\u586b\u5145,\u5bf9\u8f93\u5165\u7684\u6807\u7b7e\u8fdb\u884c\u586b\u5145\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u56fe\u7247\u90fd\u6709\u76f8\u540c\u6570\u91cf\u7684\u6807\u7b7e\u3002padding_size\u8868\u793a\u586b\u5145\u540e\u6807\u7b7e\u7684\u6570\u91cf\uff0cpadding_value\u8868\u793a\u586b\u5145\u7684\u503c\u3002</p> </li> <li> <p><code>image_norm</code>:\u56fe\u7247\u5f52\u4e00\u5316,\u5c06\u8f93\u5165\u7684\u56fe\u7247\u50cf\u7d20\u503c\u4ece[0, 255]\u8303\u56f4\u5185\u7f29\u653e\u5230[0, 1]\u8303\u56f4\u5185\u3002</p> </li> <li> <p><code>image_transpose</code>:\u56fe\u7247\u53d8\u6362,\u5c06\u8f93\u5165\u7684\u56fe\u7247\u4eceBGR\u683c\u5f0f\u8f6c\u6362\u4e3aRGB\u683c\u5f0f\uff0c\u5e76\u5c06\u56fe\u7247\u7684\u901a\u9053\u6570\u4eceHWC\u683c\u5f0f\u8f6c\u6362\u4e3aCHW\u683c\u5f0f\u3002</p> </li> </ul>"},{"location":"tutorials/data_augmentation/#-_1","title":"\u6570\u636e\u589e\u5f3a--\u81ea\u5b9a\u4e49","text":"<p>\u7f16\u5199\u6307\u5357\uff1a - \u5728mindyolo/data/dataset.py\u6587\u4ef6COCODataset\u7c7b\u4e2d\u6dfb\u52a0\u81ea\u5b9a\u4e49\u6570\u636e\u589e\u5f3a\u65b9\u6cd5 - \u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u7684\u8f93\u5165\u901a\u5e38\u5305\u542b\u56fe\u7247\u3001\u6807\u7b7e\u548c\u81ea\u5b9a\u4e49\u53c2\u6570\u3002 - \u7f16\u5199\u51fd\u6570\u4f53\u5185\u5bb9\uff0c\u81ea\u5b9a\u4e49\u8f93\u51fa\uff0c\u5982\u4e0b <pre><code>#mindyolo/data/dataset.py\n    def augmentation_fn(self, image, labels,args):\n        ...\n        return image, labels\n</code></pre> \u4f7f\u7528\u6307\u5357\uff1a - \u5728\u6a21\u578b\u7684yaml\u6587\u4ef6\u4e2d\uff0c\u4ee5\u5b57\u5178\u7684\u5f62\u5f0f\u5b9a\u4e49\u6b64\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u8be6\u60c5\u8bf7\u53c2\u89c1\u672c\u6587\u4e0a\u8ff0\u6307\u5bfc\u3002</p>"},{"location":"tutorials/deployment/","title":"Deployment","text":""},{"location":"tutorials/deployment/#mindyolo","title":"MindYOLO\u90e8\u7f72","text":""},{"location":"tutorials/deployment/#_1","title":"\u4f9d\u8d56","text":"<pre><code>pip install -r requirement.txt\n</code></pre>"},{"location":"tutorials/deployment/#mindspore-lite","title":"MindSpore Lite\u73af\u5883\u51c6\u5907","text":"<p>\u53c2\u8003\uff1aLite\u73af\u5883\u914d\u7f6e     \u6ce8\u610f\uff1aMindSpore Lite\u9002\u914d\u7684python\u73af\u5883\u4e3a3.7\uff0c\u8bf7\u5728\u5b89\u88c5Lite\u524d\u51c6\u5907\u597dpython3.7\u7684\u73af\u5883     1. \u6839\u636e\u73af\u5883\uff0c\u4e0b\u8f7d\u914d\u5957\u7684tar.gz\u5305\u548cwhl\u5305    2. \u89e3\u538btar.gz\u5305\u5e76\u5b89\u88c5\u5bf9\u5e94\u7248\u672c\u7684whl\u5305    <pre><code>tar -zxvf mindspore_lite-2.0.0a0-cp37-cp37m-{os}_{platform}_64.tar.gz\npip install mindspore_lite-2.0.0a0-cp37-cp37m-{os}_{platform}_64.whl\n</code></pre>    3. \u914d\u7f6eLite\u7684\u73af\u5883\u53d8\u91cf    LITE_HOME\u4e3atar.gz\u89e3\u538b\u51fa\u7684\u6587\u4ef6\u5939\u8def\u5f84\uff0c\u63a8\u8350\u4f7f\u7528\u7edd\u5bf9\u8def\u5f84    <pre><code>export LITE_HOME=/path/to/mindspore-lite-{version}-{os}-{platform}\nexport LD_LIBRARY_PATH=$LITE_HOME/runtime/lib:$LITE_HOME/tools/converter/lib:$LD_LIBRARY_PATH\nexport PATH=$LITE_HOME/tools/converter/converter:$LITE_HOME/tools/benchmark:$PATH\n</code></pre></p>"},{"location":"tutorials/deployment/#_2","title":"\u5feb\u901f\u5f00\u59cb","text":""},{"location":"tutorials/deployment/#_3","title":"\u6a21\u578b\u8f6c\u6362","text":"<p>ckpt\u6a21\u578b\u8f6c\u4e3amindir\u6a21\u578b\uff0c\u6b64\u6b65\u9aa4\u53ef\u5728CPU/Ascend910\u4e0a\u8fd0\u884c    <pre><code>python ./deploy/export.py --config ./path_to_config/model.yaml --weight ./path_to_ckpt/weight.ckpt --per_batch_size 1 --file_format MINDIR --device_target [CPU/Ascend]\ne.g.\n# \u5728CPU\u4e0a\u8fd0\u884c\npython ./deploy/export.py --config ./configs/yolov5/yolov5n.yaml --weight yolov5n_300e_mAP273-9b16bd7b.ckpt --per_batch_size 1 --file_format MINDIR --device_target CPU\n# \u5728Ascend\u4e0a\u8fd0\u884c\npython ./deploy/export.py --config ./configs/yolov5/yolov5n.yaml --weight yolov5n_300e_mAP273-9b16bd7b.ckpt --per_batch_size 1 --file_format MINDIR --device_target Ascend\n</code></pre></p>"},{"location":"tutorials/deployment/#lite-test","title":"Lite Test","text":"<pre><code>python deploy/test.py --model_type Lite --model_path ./path_to_mindir/weight.mindir --config ./path_to_config/yolo.yaml\ne.g.\npython deploy/test.py --model_type Lite --model_path ./yolov5n.mindir --config ./configs/yolov5/yolov5n.yaml\n</code></pre>"},{"location":"tutorials/deployment/#lite-predict","title":"Lite Predict","text":"<pre><code>python ./deploy/predict.py --model_type Lite --model_path ./path_to_mindir/weight.mindir --config ./path_to_conifg/yolo.yaml --image_path ./path_to_image/image.jpg\ne.g.\npython deploy/predict.py --model_type Lite --model_path ./yolov5n.mindir --conifg ./configs/yolov5/yolov5n.yaml --image_path ./coco/image/val2017/image.jpg\n</code></pre>"},{"location":"tutorials/deployment/#_4","title":"\u811a\u672c\u8bf4\u660e","text":"<ul> <li>predict.py \u652f\u6301\u5355\u5f20\u56fe\u7247\u63a8\u7406</li> <li>test.py \u652f\u6301COCO\u6570\u636e\u96c6\u63a8\u7406</li> </ul>"},{"location":"tutorials/deployment/#mindx","title":"MindX\u90e8\u7f72","text":"<p>\u67e5\u770b MINDX</p>"},{"location":"tutorials/deployment/#_5","title":"\u6807\u51c6\u548c\u652f\u6301\u7684\u6a21\u578b\u5e93","text":"<ul> <li> YOLOv7</li> <li> YOLOv5</li> <li> YOLOv3</li> <li> YOLOv8</li> <li> YOLOv4</li> <li> YOLOX</li> </ul> Name Scale Context ImageSize Dataset Box mAP (%) Params FLOPs Recipe Download YOLOv8 N D310x1-G 640 MS COCO 2017 37.2 3.2M 8.7G yaml ckpt mindir YOLOv8 S D310x1-G 640 MS COCO 2017 44.6 11.2M 28.6G yaml ckpt mindir YOLOv8 M D310x1-G 640 MS COCO 2017 50.5 25.9M 78.9G yaml ckpt mindir YOLOv8 L D310x1-G 640 MS COCO 2017 52.8 43.7M 165.2G yaml ckpt mindir YOLOv8 X D310x1-G 640 MS COCO 2017 53.7 68.2M 257.8G yaml ckpt mindir YOLOv7 Tiny D310x1-G 640 MS COCO 2017 37.5 6.2M 13.8G yaml ckpt mindir YOLOv7 L D310x1-G 640 MS COCO 2017 50.8 36.9M 104.7G yaml ckpt mindir YOLOv7 X D310x1-G 640 MS COCO 2017 52.4 71.3M 189.9G yaml ckpt mindir YOLOv5 N D310x1-G 640 MS COCO 2017 27.3 1.9M 4.5G yaml ckpt mindir YOLOv5 S D310x1-G 640 MS COCO 2017 37.6 7.2M 16.5G yaml ckpt mindir YOLOv5 M D310x1-G 640 MS COCO 2017 44.9 21.2M 49.0G yaml ckpt mindir YOLOv5 L D310x1-G 640 MS COCO 2017 48.5 46.5M 109.1G yaml ckpt mindir YOLOv5 X D310x1-G 640 MS COCO 2017 50.5 86.7M 205.7G yaml ckpt mindir YOLOv4 CSPDarknet53 D310x1-G 608 MS COCO 2017 45.4 27.6M 52G yaml ckpt mindir YOLOv4 CSPDarknet53(silu) D310x1-G 640 MS COCO 2017 45.8 27.6M 52G yaml ckpt mindir YOLOv3 Darknet53 D310x1-G 640 MS COCO 2017 45.5 61.9M 156.4G yaml ckpt mindir YOLOX N D310x1-G 416 MS COCO 2017 24.1 0.9M 1.1G yaml ckpt mindir YOLOX Tiny D310x1-G 416 MS COCO 2017 33.3 5.1M 6.5G yaml ckpt mindir YOLOX S D310x1-G 640 MS COCO 2017 40.7 9.0M 26.8G yaml ckpt mindir YOLOX M D310x1-G 640 MS COCO 2017 46.7 25.3M 73.8G yaml ckpt mindir YOLOX L D310x1-G 640 MS COCO 2017 49.2 54.2M 155.6G yaml ckpt mindir YOLOX X D310x1-G 640 MS COCO 2017 51.6 99.1M 281.9G yaml ckpt mindir YOLOX Darknet53 D310x1-G 640 MS COCO 2017 47.7 63.7M 185.3G yaml ckpt mindir"},{"location":"tutorials/finetune/","title":"Finetune","text":""},{"location":"tutorials/finetune/#finetune_1","title":"\u81ea\u5b9a\u4e49\u6570\u636e\u96c6finetune\u6d41\u7a0b","text":"<p>\u672c\u6587\u4ee5\u5b89\u5168\u5e3d\u4f69\u6234\u68c0\u6d4b\u6570\u636e\u96c6(SHWD)\u4e3a\u4f8b\uff0c\u4ecb\u7ecd\u81ea\u5b9a\u4e49\u6570\u636e\u96c6\u5728MindYOLO\u4e0a\u8fdb\u884cfinetune\u7684\u4e3b\u8981\u6d41\u7a0b\u3002</p>"},{"location":"tutorials/finetune/#_1","title":"\u6570\u636e\u96c6\u683c\u5f0f\u8f6c\u6362","text":"<p>SHWD\u6570\u636e\u96c6\u91c7\u7528voc\u683c\u5f0f\u7684\u6570\u636e\u6807\u6ce8\uff0c\u5176\u6587\u4ef6\u76ee\u5f55\u5982\u4e0b\u6240\u793a\uff1a <pre><code>             ROOT_DIR\n                \u251c\u2500\u2500 Annotations\n                \u2502        \u251c\u2500\u2500 000000.xml\n                \u2502        \u2514\u2500\u2500 000002.xml\n                \u251c\u2500\u2500 ImageSets\n                \u2502       \u2514\u2500\u2500 Main\n                \u2502             \u251c\u2500\u2500 test.txt\n                \u2502             \u251c\u2500\u2500 train.txt\n                \u2502             \u251c\u2500\u2500 trainval.txt\n                \u2502             \u2514\u2500\u2500 val.txt\n                \u2514\u2500\u2500 JPEGImages\n                        \u251c\u2500\u2500 000000.jpg\n                        \u2514\u2500\u2500 000002.jpg\n</code></pre> \u5176\u4e2d\uff0cImageSets/Main\u6587\u4ef6\u4e0b\u7684txt\u6587\u4ef6\u4e2d\u6bcf\u884c\u4ee3\u8868\u76f8\u5e94\u5b50\u96c6\u4e2d\u5355\u5f20\u56fe\u7247\u4e0d\u542b\u540e\u7f00\u7684\u6587\u4ef6\u540d\uff0c\u4f8b\u5982\uff1a <pre><code>000002\n000005\n000019\n000022\n000027\n000034\n</code></pre></p> <p>\u7531\u4e8eMindYOLO\u5728\u9a8c\u8bc1\u9636\u6bb5\u9009\u7528\u56fe\u7247\u540d\u79f0\u4f5c\u4e3aimage_id\uff0c\u56e0\u6b64\u56fe\u7247\u540d\u79f0\u53ea\u80fd\u4e3a\u6570\u503c\u7c7b\u578b\uff0c\u800c\u4e0d\u80fd\u4e3a\u5b57\u7b26\u4e32\u7c7b\u578b\uff0c\u8fd8\u9700\u8981\u5bf9\u56fe\u7247\u8fdb\u884c\u6539\u540d\u3002\u5bf9SHWD\u6570\u636e\u96c6\u683c\u5f0f\u7684\u8f6c\u6362\u5305\u542b\u5982\u4e0b\u6b65\u9aa4\uff1a * \u5c06\u56fe\u7247\u590d\u5236\u5230\u76f8\u5e94\u7684\u8def\u5f84\u4e0b\u5e76\u6539\u540d * \u5728\u6839\u76ee\u5f55\u4e0b\u76f8\u5e94\u7684txt\u6587\u4ef6\u4e2d\u5199\u5165\u8be5\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84 * \u89e3\u6790xml\u6587\u4ef6\uff0c\u5728\u76f8\u5e94\u8def\u5f84\u4e0b\u751f\u6210\u5bf9\u5e94\u7684txt\u6807\u6ce8\u6587\u4ef6 * \u9a8c\u8bc1\u96c6\u8fd8\u9700\u751f\u6210\u6700\u7ec8\u7684json\u6587\u4ef6</p> <p>\u8be6\u7ec6\u5b9e\u73b0\u53ef\u53c2\u8003convert_shwd2yolo.py\u3002\u8fd0\u884c\u65b9\u5f0f\u5982\u4e0b\uff1a</p> <pre><code>python examples/finetune_SHWD/convert_shwd2yolo.py --root_dir /path_to_shwd/SHWD\n</code></pre> <p>\u8fd0\u884c\u4ee5\u4e0a\u547d\u4ee4\u5c06\u5728\u4e0d\u6539\u53d8\u539f\u6570\u636e\u96c6\u7684\u524d\u63d0\u4e0b\uff0c\u5728\u540c\u7ea7\u76ee\u5f55\u751f\u6210yolo\u683c\u5f0f\u7684SHWD\u6570\u636e\u96c6\u3002</p>"},{"location":"tutorials/finetune/#_2","title":"\u9884\u8bad\u7ec3\u6a21\u578b\u6587\u4ef6\u8f6c\u6362","text":"<p>\u7531\u4e8eSHWD\u6570\u636e\u96c6\u53ea\u67097000+\u5f20\u56fe\u7247\uff0c\u9009\u62e9yolov7-tiny\u8fdb\u884c\u8be5\u6570\u636e\u96c6\u7684\u8bad\u7ec3\uff0c\u53ef\u4e0b\u8f7dMindYOLO\u63d0\u4f9b\u7684\u5728coco\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u6587\u4ef6\u4f5c\u4e3a\u9884\u8bad\u7ec3\u6a21\u578b\u3002\u7531\u4e8ecoco\u6570\u636e\u96c6\u542b\u670980\u79cd\u7269\u4f53\u7c7b\u522b\uff0cSHWD\u6570\u636e\u96c6\u53ea\u6709\u4e24\u7c7b\uff0c\u6a21\u578b\u7684\u6700\u540e\u4e00\u5c42head\u5c42\u8f93\u51fa\u4e0e\u7c7b\u522b\u6570nc\u6709\u5173\uff0c\u56e0\u6b64\u9700\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u6587\u4ef6\u7684\u6700\u540e\u4e00\u5c42\u53bb\u6389\uff0c \u53ef\u53c2\u8003convert_yolov7-tiny_pretrain_ckpt.py\u3002\u8fd0\u884c\u65b9\u5f0f\u5982\u4e0b\uff1a</p> <pre><code>python examples/finetune_SHWD/convert_yolov7-tiny_pretrain_ckpt.py\n</code></pre>"},{"location":"tutorials/finetune/#finetune_2","title":"\u6a21\u578b\u5fae\u8c03(Finetune)","text":"<p>\u7b80\u8981\u7684\u8bad\u7ec3\u6d41\u7a0b\u53ef\u53c2\u8003finetune_shwd.py</p> <ul> <li>\u5728\u591a\u5361NPU/GPU\u4e0a\u8fdb\u884c\u5206\u5e03\u5f0f\u6a21\u578b\u8bad\u7ec3\uff0c\u4ee58\u5361\u4e3a\u4f8b:</li> </ul> <pre><code>mpirun --allow-run-as-root -n 8 python examples/finetune_SHWD/finetune_shwd.py --config ./examples/finetune_SHWD/yolov7-tiny_shwd.yaml --is_parallel True\n</code></pre> <ul> <li>\u5728\u5355\u5361NPU/GPU/CPU\u4e0a\u8bad\u7ec3\u6a21\u578b\uff1a</li> </ul> <pre><code>python examples/finetune_SHWD/finetune_shwd.py --config ./examples/finetune_SHWD/yolov7-tiny_shwd.yaml </code></pre> <p>\u6ce8\u610f\uff1a\u76f4\u63a5\u7528yolov7-tiny\u9ed8\u8ba4coco\u53c2\u6570\u5728SHWD\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u53ef\u53d6\u5f97AP50 87.0\u7684\u7cbe\u5ea6\u3002\u5c06lr_init\u53c2\u6570\u75310.01\u6539\u4e3a0.001\uff0c\u5373\u53ef\u5b9e\u73b0ap50\u4e3a89.2\u7684\u7cbe\u5ea6\u7ed3\u679c\u3002</p>"},{"location":"tutorials/modelarts/","title":"Modelarts","text":""},{"location":"tutorials/modelarts/#mindyolo-cloud-training-quick-start-guide","title":"MindYOLO Cloud Training Quick Start Guide","text":"<p>This article introduces MindYOLO training with the OPENI Qizhi Platform. .</p>"},{"location":"tutorials/modelarts/#external-project-migration","title":"External Project Migration","text":"<p>Click on the plus icon in the upper right corner of the main page and select \"New Migration\" to migrate MindYOLO from GitHub to the OPENI platform.</p> <p>Enter the URL of MindYOLO to initiate the migration.</p>"},{"location":"tutorials/modelarts/#prepare-the-dataset","title":"Prepare the Dataset","text":"<p>You can upload your own dataset or linked existing datasets on the platform.</p> <p>When uploading a personal dataset, select NPU as the cluster option.</p>"},{"location":"tutorials/modelarts/#prepare-pretrained-models-optional","title":"Prepare Pretrained Models (Optional)","text":"<p>If you want to load pretrained weights, you can add them in the \"Models\" tab.</p> <p>When importing local models, specify the framework as MindSpore.</p>"},{"location":"tutorials/modelarts/#create-a-new-training-task","title":"Create a New Training Task","text":"<p>Select \"Train Task\", and then click \"New Train Task.\"</p> <p>In the \"Basic Info\" section, select Ascend NPU as the computing resources.</p> <p>Set the parameters and add the runtime parameters.</p> <ul> <li>If you want to load pretrained weights, select the uploaded model file in the \"Model\" section, and add the \"ckpt_dir\" parameter in the runtime parameters. The parameter value should be \"/cache/*.ckpt\" where * represents the actual filename.</li> <li>In the AI Engine section, select MindSpore-1.8.1-aarch64, and set the start file as train.py.</li> <li>Add the \"enable_modelarts\" parameter with a value of True in the runtime parameters.</li> <li>Specify the specific model in the \"config\" parameter in the runtime parameters. The parameter value prefix should be \"/home/work/user-job-dir/\" followed by the runtime version number. The runtime version number is typically V0001 for a new training task.</li> </ul> <p>In a distributed training scenario, select the desired number of cards in the \"Specifications\" section and add the \"is_parallel\" parameter with a value of True in the runtime parameters.</p>"},{"location":"tutorials/modelarts/#modify-an-existing-training-task","title":"Modify an Existing Training Task","text":"<p>Click on the \"Modify\" button for an existing training task to make parameter modifications based on the existing task and run a new training task.</p> <p>Note: The runtime version number should be the parents version number + 1.</p>"},{"location":"tutorials/modelarts/#check-status","title":"Check Status","text":"<p>Click on the corresponding task name to view configuration information, logs, resource usage, and download results.</p>"},{"location":"tutorials/quick_start/","title":"Quick Start","text":""},{"location":"tutorials/quick_start/#getting-started-with-mindyolo","title":"Getting Started with MindYOLO","text":"<p>This document provides a brief introduction to the usage of built-in command-line tools in MindYOLO.</p>"},{"location":"tutorials/quick_start/#inference-demo-with-pre-trained-models","title":"Inference Demo with Pre-trained Models","text":"<ol> <li>Pick a model and its config file from the   model zoo,   such as, <code>./configs/yolov7/yolov7.yaml</code>.</li> <li>Download the corresponding pre-trained checkpoint from the model zoo of each model.</li> <li>To run YOLO object detection with the built-in configs, please run:</li> </ol> <pre><code># Run with Ascend (By default)\npython demo/predict.py --config ./configs/yolov7/yolov7.yaml --weight=/path_to_ckpt/WEIGHT.ckpt --image_path /path_to_image/IMAGE.jpg\n\n# Run with GPU\npython demo/predict.py --config ./configs/yolov7/yolov7.yaml --weight=/path_to_ckpt/WEIGHT.ckpt --image_path /path_to_image/IMAGE.jpg --device_target=GPU\n</code></pre> <p>For details of the command line arguments, see <code>demo/predict.py -h</code> or look at its source code to understand their behavior. Some common arguments are: * To run on cpu, modify device_target to CPU. * The results will be saved in <code>./detect_results</code></p>"},{"location":"tutorials/quick_start/#training-evaluation-in-command-line","title":"Training &amp; Evaluation in Command Line","text":"<ul> <li>Prepare your dataset in YOLO format. If trained with COCO (YOLO format), prepare it from yolov5 or the darknet.</li> </ul> <pre><code>  coco/\n    {train,val}2017.txt\n    annotations/\n      instances_{train,val}2017.json\n    images/\n      {train,val}2017/\n          00000001.jpg\n          ...\n          # image files that are mentioned in the corresponding train/val2017.txt\n    labels/\n      {train,val}2017/\n          00000001.txt\n          ...\n          # label files that are mentioned in the corresponding train/val2017.txt\n</code></pre> <ul> <li> <p>To train a model on 8 NPUs/GPUs:   <pre><code>mpirun --allow-run-as-root -n 8 python train.py --config ./configs/yolov7/yolov7.yaml  --is_parallel True\n</code></pre></p> </li> <li> <p>To train a model on 1 NPU/GPU/CPU:   <pre><code>python train.py --config ./configs/yolov7/yolov7.yaml \n</code></pre></p> </li> <li> <p>To evaluate a model's performance:   <pre><code>python test.py --config ./configs/yolov7/yolov7.yaml --weight /path_to_ckpt/WEIGHT.ckpt\n</code></pre> Notes: (1) The default hyper-parameter is used for 8-card training, and some parameters need to be adjusted in the case of a single card. (2) The default device is Ascend, and you can modify it by specifying 'device_target' as Ascend/GPU/CPU, as these are currently supported.</p> </li> <li>For more options, see <code>train/test.py -h</code>.</li> </ul>"},{"location":"tutorials/quick_start/#deployment","title":"Deployment","text":"<p>See here.</p>"},{"location":"tutorials/quick_start/#to-use-mindyolo-apis-in-your-code","title":"To use MindYOLO APIs in Your Code","text":"<p>To be supplemented.</p>"},{"location":"tutorials/train_process/","title":"\u6df1\u5ea6\u5b66\u4e60Train and Eval \u6d41\u7a0b\u89e3\u6790","text":"<p>\u5171\u6709\u4ee5\u4e0b8\u4e2a\u6b65\u9aa4:</p> <ul> <li>\u521b\u5efa\u7f51\u7edc\u548c\u521d\u59cb\u5316 </li> <li>\u521b\u5efaDataLoader </li> <li>\u521b\u5efa\u635f\u5931\u51fd\u6570 </li> <li>\u521b\u5efa\u4f18\u5316\u5668\uff0c\u5e76\u8bbe\u7f6e\u76f8\u5173\u53c2\u6570 </li> <li>\u521b\u5efaTrain Step\u51fd\u6570 </li> <li>\u521b\u5efa\u56de\u8c03\u51fd\u6570 </li> <li>\u521b\u5efaTest\u7cbe\u5ea6\u8ba1\u7b97\u51fd\u6570 </li> <li>\u521b\u5efaTrainer\u5bf9\u8c61\uff0c\u5e76\u8c03\u7528train\u65b9\u6cd5\u6765\u8bad\u7ec3\u6a21\u578b</li> </ul>"},{"location":"tutorials/train_process/#1","title":"1.\u521b\u5efa\u7f51\u7edc\u548c\u521d\u59cb\u5316","text":"<pre><code>    # Create Network\n    args.network.recompute = args.recompute\n    args.network.recompute_layers = args.recompute_layers\n    network = create_model(\n        model_name=args.network.model_name,\n        model_cfg=args.network,\n        num_classes=args.data.nc,\n        sync_bn=args.sync_bn,\n    )\n</code></pre>"},{"location":"tutorials/train_process/#2dataloader","title":"2.\u521b\u5efaDataLoader","text":"<ul> <li>\u83b7\u53d6\u8bad\u7ec3\u6570\u636e\u7684\u589e\u5f3a\u51fd\u6570\u548cepoch\u7b49\u4fe1\u606f\uff1a <pre><code>transforms = args.data.train_transforms\nstage_epochs = [args.epochs,] if not isinstance(transforms, dict) else transforms['stage_epochs']\nstage_transforms = [transforms,] if not isinstance(transforms, dict) else transforms['trans_list']\n</code></pre> \u5176\u4e2dstage_epochs\u8868\u793a\u5404\u9636\u6bb5\u7684epoch\u6570\u3002stage_transforms\u8868\u793a\u5404\u4e2a\u9636\u6bb5\u7684\u53d8\u6362\u51fd\u6570\uff0c\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u6bcf\u4e2a\u5143\u7d20\u662f\u4e00\u4e2a\u9636\u6bb5\u7684\u6570\u636e\u589e\u5f3a\u51fd\u6570\u5217\u8868\u3002</li> <li>\u521b\u5efaTraining Dataset\u548cDataLoader <pre><code>  for stage in range(len(stage_epochs)):\n        _dataset = COCODataset(\n            dataset_path=args.data.train_set,\n            img_size=args.img_size,\n            transforms_dict=stage_transforms[stage],\n            is_training=True,\n            augment=True,\n            rect=args.rect,\n            single_cls=args.single_cls,\n            batch_size=args.total_batch_size,\n            stride=max(args.network.stride),\n        )\n        _dataloader = create_loader(\n            dataset=_dataset,\n            batch_collate_fn=_dataset.train_collate_fn,\n            dataset_column_names=_dataset.dataset_column_names,\n            batch_size=args.per_batch_size,\n            epoch_size=stage_epochs[stage],\n            rank=args.rank,\n            rank_size=args.rank_size,\n            shuffle=True,\n            drop_remainder=True,\n            num_parallel_workers=args.data.num_parallel_workers,\n            python_multiprocessing=True,\n        )\n        stage_dataloaders.append(_dataloader)\n</code></pre></li> <li>\u5408\u5e76DataLoader <pre><code>    dataloader = stage_dataloaders[0] if len(stage_dataloaders) == 1 else ms.dataset.ConcatDataset(stage_dataloaders)\n</code></pre></li> <li>\u521b\u5efaTesting Dataset\u548cDataLoader\uff08\u53ef\u9009\uff0c\u7531run_eval\u53c2\u6570\u63a7\u5236\uff09</li> </ul>"},{"location":"tutorials/train_process/#3","title":"3.\u521b\u5efa\u635f\u5931\u51fd\u6570","text":"<pre><code>    loss_fn = create_loss(\n        **args.loss, anchors=args.network.get(\"anchors\", 1), stride=args.network.stride, nc=args.data.nc\n    )\n    ms.amp.auto_mixed_precision(loss_fn, amp_level=\"O0\" if args.keep_loss_fp32 else args.ms_amp_level)\n</code></pre>"},{"location":"tutorials/train_process/#4","title":"4.\u521b\u5efa\u4f18\u5316\u5668\uff0c\u5e76\u8bbe\u7f6e\u76f8\u5173\u53c2\u6570","text":"<pre><code>    # Create Optimizer\n    args.optimizer.steps_per_epoch = steps_per_epoch\n    lr = create_lr_scheduler(**args.optimizer)\n    params = create_group_param(params=network.trainable_params(), **args.optimizer)\n    optimizer = create_optimizer(params=params, lr=lr, **args.optimizer)\n    warmup_momentum = create_warmup_momentum_scheduler(**args.optimizer)\n</code></pre>"},{"location":"tutorials/train_process/#5train-step","title":"5.\u521b\u5efaTrain Step\u51fd\u6570","text":"<p><pre><code>    # Create train_step_fn\n    reducer = get_gradreducer(args.is_parallel, optimizer.parameters)\n    scaler = get_loss_scaler(args.ms_loss_scaler, scale_value=args.ms_loss_scaler_value)\n    train_step_fn = create_train_step_fn(\n        network=network,\n        loss_fn=loss_fn,\n        optimizer=optimizer,\n        loss_ratio=args.rank_size,\n        scaler=scaler,\n        reducer=reducer,\n        ema=ema,\n        overflow_still_update=args.overflow_still_update,\n        ms_jit=args.ms_jit,\n    )\n</code></pre> create_train_step_fn\u7528\u6765\u63a5\u6536\u7f51\u7edc\u3001\u635f\u5931\u51fd\u6570\u3001\u4f18\u5316\u5668\u7b49\u53c2\u6570\uff0c\u5b9a\u4e49\u524d\u5411\u8fc7\u7a0b\u3001\u68af\u5ea6\u8ba1\u7b97\u3001\u53c2\u6570\u66f4\u65b0\u3002</p>"},{"location":"tutorials/train_process/#6","title":"6.\u521b\u5efa\u56de\u8c03\u51fd\u6570","text":"<p><pre><code>    # Create callbacks\n    if args.summary:\n        args.callback.append({\"name\": \"SummaryCallback\"})\n    if args.profiler:\n        args.callback.append({\"name\": \"ProfilerCallback\", \"profiler_step_num\": args.profiler_step_num})\n    callback_fns = create_callback(args.callback)\n</code></pre> \u521b\u5efa\u56de\u8c03\u51fd\u6570\u5217\u8868\u3002\u5176\u4e2dsummary\u53c2\u6570\u8868\u793a\u662f\u5426\u6536\u96c6\u8bad\u7ec3loss\u4fe1\u606f\uff0cprofiler\u53c2\u6570\u8868\u793a\u662f\u5426\u6536\u96c6\u6027\u80fd\u6570\u636e\u3002</p>"},{"location":"tutorials/train_process/#7test","title":"7.\u521b\u5efaTest\u7cbe\u5ea6\u8ba1\u7b97\u51fd\u6570","text":"<p><pre><code>    # Create test function for run eval while train\n    if args.run_eval:\n        is_coco_dataset = \"coco\" in args.data.dataset_name\n        test_fn = partial(\n            test,\n            dataloader=eval_dataloader,\n            anno_json_path=os.path.join(\n                args.data.val_set[: -len(args.data.val_set.split(\"/\")[-1])], \"annotations/instances_val2017.json\"\n            ),\n            conf_thres=args.conf_thres,\n            iou_thres=args.iou_thres,\n            conf_free=args.conf_free,\n            nms_time_limit=args.nms_time_limit,\n            is_coco_dataset=is_coco_dataset,\n            imgIds=None if not is_coco_dataset else eval_dataset.imgIds,\n            per_batch_size=args.per_batch_size,\n            rank=args.rank,\n            rank_size=args.rank_size,\n            save_dir=args.save_dir,\n            synchronizer=Synchronizer(args.rank_size) if args.rank_size &gt; 1 else None,\n        )\n    else:\n        test_fn = None\n</code></pre> \u8fd9\u4e2a\u6d4b\u8bd5\u51fd\u6570\u7528\u4e8e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u6a21\u578b\u8bc4\u4f30\uff0c\u5b83\u5c06\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u8bb0\u5f55\u4e0b\u6765\u3002</p>"},{"location":"tutorials/train_process/#8trainertrain","title":"8.\u521b\u5efaTrainer\u5bf9\u8c61\uff0c\u5e76\u8c03\u7528train\u65b9\u6cd5\u6765\u8bad\u7ec3\u6a21\u578b","text":"<p><pre><code>trainer = create_trainer(\n    model_name=model_name,\n    train_step_fn=train_step_fn,\n    scaler=scaler,\n    dataloader=dataloader,\n    steps_per_epoch=steps_per_epoch,\n    network=network,\n    loss_fn=loss_fn,\n    ema=ema,\n    optimizer=optimizer,\n    callback=callback_fns,\n    reducer=reducer,\n    data_sink=args.ms_datasink,\n    profiler=args.profiler\n)\n\nif not args.ms_datasink:\n    trainer.train(...)\nelse:\n    trainer.train_with_datasink(...)\n</code></pre> \u63d0\u4f9b\u666e\u901a\u8bad\u7ec3\u65b9\u5f0f\u548c\u6570\u636e\u4e0b\u6c89\u8bad\u7ec3\u65b9\u5f0f\uff0c\u7531\u53c2\u6570ms_datasink\u63a7\u5236\u3002</p>"},{"location":"zh/","title":"\u4e3b\u9875","text":""},{"location":"zh/#mindyolo","title":"MindYOLO","text":"<p>MindYOLO\u662fMindSpore Lab\u5f00\u53d1\u7684AI\u5957\u4ef6\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684YOLO\u7cfb\u5217\u7b97\u6cd5\uff0c\u67e5\u770b\u652f\u6301\u7684\u6a21\u578b\u7b97\u6cd5\u3002</p> <p>MindYOLO\u4f7f\u7528Python\u8bed\u8a00\u7f16\u5199\uff0c\u57fa\u4e8e MindSpore AI\u6846\u67b6\u5f00\u53d1\u3002</p> <p>master \u5206\u652f\u914d\u5957 MindSpore 2.0\u3002</p> <p></p>"},{"location":"zh/#_1","title":"\u65b0\u7279\u6027","text":"<ul> <li>2023/06/15</li> </ul> <ol> <li>\u652f\u6301 YOLOv3/v4/v5/v7/v8/X \u7b496\u4e2a\u6a21\u578b\uff0c\u53d1\u5e03\u4e8623\u4e2a\u6a21\u578bweights\uff0c\u8be6\u60c5\u8bf7\u53c2\u8003 MODEL ZOO\u3002</li> <li>\u914d\u5957 MindSpore 2.0\u3002</li> <li>\u652f\u6301 MindSpore lite 2.0 \u63a8\u7406\u3002</li> <li>\u65b0\u7684\u6559\u7a0b\u6587\u6863\u4e0a\u7ebf\uff01</li> </ol>"},{"location":"zh/#_2","title":"\u57fa\u51c6\u548c\u6a21\u578b\u4ed3\u5e93","text":"<p>\u67e5\u770b MODEL ZOO.</p> \u652f\u6301\u7684\u7b97\u6cd5 <ul> <li> YOLOv8</li> <li> YOLOv7</li> <li> YOLOX</li> <li> YOLOv5</li> <li> YOLOv4</li> <li> YOLOv3</li> </ul>"},{"location":"zh/#_3","title":"\u5b89\u88c5","text":""},{"location":"zh/#_4","title":"\u4f9d\u8d56","text":"<ul> <li>mindspore &gt;= 2.0</li> <li>numpy &gt;= 1.17.0</li> <li>pyyaml &gt;= 5.3</li> <li>openmpi 4.0.3 (for distributed mode)</li> </ul> <p>\u5b89\u88c5\u8fd9\u4e9b\u4f9d\u8d56\uff0c\u8bf7\u6267\u884c\u4ee5\u4e0b\u547d\u4ee4</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>\u7136\u540e\u6309\u7167\u5b98\u65b9\u8bf4\u660e\u8f7b\u677e\u5b89\u88c5MindSpore\uff0c\u4f60\u53ef\u4ee5\u5728\u5176\u4e2d\u9009\u62e9\u6700\u9002\u5408\u7684\u786c\u4ef6\u5e73\u53f0\u3002\u8981\u5728\u5206\u5e03\u5f0f\u6a21\u5f0f\u4e0b\u8fd0\u884c\uff0c\u9700\u8981\u5b89\u88c5openmpi\u3002 </p> <p>\u26a0\ufe0f \u5f53\u524d\u7248\u672c\u4ec5\u652f\u6301Ascend\u5e73\u53f0\uff0cGPU\u5e73\u53f0\u5c06\u5728\u540e\u7eed\u7248\u672c\u4e2d\u652f\u6301\u3002</p>"},{"location":"zh/#_5","title":"\u5feb\u901f\u5165\u95e8","text":"<p>\u67e5\u770b GETTING STARTED</p>"},{"location":"zh/#mindyolo_1","title":"\u4e86\u89e3 MindYOLO \u7684\u66f4\u591a\u4fe1\u606f","text":"<p>\u656c\u8bf7\u671f\u5f85</p>"},{"location":"zh/#_6","title":"\u6ce8\u610f","text":"<p>\u26a0\ufe0f\u5f53\u524d\u7248\u672c\u57fa\u4e8eGRAPH\u7684\u9759\u6001Shape\u3002\u540e\u7eed\u5c06\u6dfb\u52a0PYNATIVE\u7684\u52a8\u6001Shape\u652f\u6301\uff0c\u656c\u8bf7\u671f\u5f85\u3002</p>"},{"location":"zh/#_7","title":"\u8d21\u732e\u65b9\u5f0f","text":"<p>\u6211\u4eec\u611f\u8c22\u5f00\u53d1\u8005\u7528\u6237\u7684\u6240\u6709\u8d21\u732e\uff0c\u5305\u62ec\u63d0issue\u548cPR\uff0c\u4e00\u8d77\u8ba9MindYOLO\u53d8\u5f97\u66f4\u597d\u3002</p> <p>\u8d21\u732e\u6307\u5357\u8bf7\u53c2\u8003CONTRIBUTING.md\u3002</p>"},{"location":"zh/#_8","title":"\u8bb8\u53ef\u8bc1","text":"<p>MindYOLO\u9075\u5faaApache License 2.0\u5f00\u6e90\u534f\u8bae\u3002</p>"},{"location":"zh/#_9","title":"\u81f4\u8c22","text":"<p>MindYOLO\u662f\u4e00\u4e2a\u6b22\u8fce\u4efb\u4f55\u8d21\u732e\u548c\u53cd\u9988\u7684\u5f00\u6e90\u9879\u76ee\u3002\u6211\u4eec\u5e0c\u671b\u901a\u8fc7\u63d0\u4f9b\u7075\u6d3b\u4e14\u6807\u51c6\u5316\u7684\u5de5\u5177\u5305\u6765\u91cd\u65b0\u5b9e\u73b0\u73b0\u6709\u65b9\u6cd5\u548c\u5f00\u53d1\u65b0\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ece\u800c\u4e3a\u4e0d\u65ad\u53d1\u5c55\u7684\u7814\u7a76\u793e\u533a\u670d\u52a1\u3002</p>"},{"location":"zh/#_10","title":"\u5f15\u7528","text":"<p>\u5982\u679c\u4f60\u89c9\u5f97MindYOLO\u5bf9\u4f60\u7684\u9879\u76ee\u6709\u5e2e\u52a9\uff0c\u8bf7\u8003\u8651\u5f15\u7528\uff1a</p> <pre><code>@misc{MindSpore Object Detection YOLO 2023,\n    title={{MindSpore Object Detection YOLO}:MindSpore Object Detection YOLO Toolbox and Benchmark},\n    author={MindSpore YOLO Contributors},\n    howpublished = {\\url{https://github.com/mindspore-lab/mindyolo}},\n    year={2023}\n}\n</code></pre>"},{"location":"zh/modelzoo/","title":"\u6a21\u578b\u4ed3\u5e93","text":""},{"location":"zh/how_to_guides/augmentation_custom/","title":"\u81ea\u5b9a\u4e49\u6570\u636e\u589e\u5f3a","text":"<p>\u8bf7\u53c2\u89c1\u6559\u7a0b/\u6570\u636e\u589e\u5f3a\u7684\u7ed3\u5c3e\uff0c\u6570\u636e\u589e\u5f3a--\u81ea\u5b9a\u4e49\u90e8\u5206</p>"},{"location":"zh/how_to_guides/data_preparation/","title":"\u6570\u636e\u51c6\u5907","text":""},{"location":"zh/how_to_guides/data_preparation/#_2","title":"\u6570\u636e\u96c6\u683c\u5f0f\u4ecb\u7ecd","text":"<p>\u9002\u7528\u4e8eMindYOLO\u7684\u6570\u636e\u96c6\u683c\u5f0f\u5177\u6709\u5982\u4e0b\u5f62\u5f0f\uff1a <pre><code>            ROOT_DIR\n                \u251c\u2500\u2500 val.txt\n                \u251c\u2500\u2500 train.txt\n                \u251c\u2500\u2500 annotations\n                \u2502        \u2514\u2500\u2500 instances_val2017.json\n                \u251c\u2500\u2500 images\n                \u2502     \u251c\u2500\u2500 train\n                \u2502     \u2502     \u251c\u2500\u2500 00000001.jpg\n                \u2502     \u2502     \u2514\u2500\u2500 00000002.jpg\n                \u2502     \u2514\u2500\u2500 val\n                \u2502          \u251c\u2500\u2500 00006563.jpg\n                \u2502          \u2514\u2500\u2500 00006564.jpg\n                \u2514\u2500\u2500 labels\n                      \u2514\u2500\u2500 train\n                            \u251c\u2500\u2500 00000001.txt\n                            \u2514\u2500\u2500 00000002.txt\n</code></pre></p> <p>\u5176\u4e2dtrain.txt\u6587\u4ef6\u6bcf\u884c\u5bf9\u5e94\u5355\u5f20\u56fe\u7247\u7684\u76f8\u5bf9\u8def\u5f84\uff0c\u4f8b\u5982\uff1a <pre><code>./images/train/00000000.jpg\n./images/train/00000001.jpg\n./images/train/00000002.jpg\n./images/train/00000003.jpg\n./images/train/00000004.jpg\n./images/train/00000005.jpg\n</code></pre> train\u6587\u4ef6\u5939\u4e0b\u7684txt\u6587\u4ef6\u4e3a\u76f8\u5e94\u56fe\u7247\u7684\u6807\u6ce8\u4fe1\u606f\uff0c\u901a\u5e38\u6bcf\u884c\u67095\u5217\uff0c\u5206\u522b\u5bf9\u5e94\u7c7b\u522bid\u4ee5\u53ca\u6807\u6ce8\u6846\u5f52\u4e00\u5316\u4e4b\u540e\u7684\u4e2d\u5fc3\u70b9\u5750\u6807xy\u548c\u5bbd\u9ad8wh\uff0c\u4f8b\u5982\uff1a <pre><code>62 0.417040 0.206280 0.403600 0.412560\n62 0.818810 0.197933 0.174740 0.189680\n39 0.684540 0.277773 0.086240 0.358960\n0 0.620220 0.725853 0.751680 0.525840\n63 0.197190 0.364053 0.394380 0.669653\n39 0.932330 0.226240 0.034820 0.076640\n</code></pre></p> <p>instances_val.json\u4e3acoco\u683c\u5f0f\u7684\u9a8c\u8bc1\u96c6\u6807\u6ce8\uff0c\u53ef\u76f4\u63a5\u8c03\u7528coco api\u7528\u4e8emap\u7684\u8ba1\u7b97\u3002</p> <p>\u4f7f\u7528MindYOLO\u5957\u4ef6\u5b8c\u6210\u81ea\u5b9a\u4e49\u6570\u636e\u96c6finetune\u7684\u5b9e\u9645\u6848\u4f8b\u53ef\u53c2\u8003README.md</p>"},{"location":"zh/how_to_guides/write_a_new_model/","title":"\u6a21\u578b\u7f16\u5199\u6307\u5357","text":"<p>\u672c\u6587\u6863\u63d0\u4f9bMindYOLO\u7f16\u5199\u81ea\u5b9a\u4e49\u6a21\u578b\u7684\u6559\u7a0b\u3002 \u5206\u4e3a\u4e09\u4e2a\u90e8\u5206\uff1a - \u6a21\u578b\u5b9a\u4e49\uff1a\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u5b9a\u4e49\u4e00\u4e2a\u7f51\u7edc\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528yaml\u6587\u4ef6\u65b9\u5f0f\u5b9a\u4e49\u4e00\u4e2a\u7f51\u7edc\u3002 - \u6ce8\u518c\u6a21\u578b\uff1a\u53ef\u9009\uff0c\u6ce8\u518c\u4e4b\u540e\u53ef\u4ee5\u5728create_model\u63a5\u53e3\u4e2d\u4f7f\u7528\u6587\u4ef6\u540d\u521b\u5efa\u81ea\u5b9a\u4e49\u7684\u6a21\u578b - \u9a8c\u8bc1: \u9a8c\u8bc1\u6a21\u578b\u662f\u5426\u53ef\u8fd0\u884c</p>"},{"location":"zh/how_to_guides/write_a_new_model/#_2","title":"\u6a21\u578b\u5b9a\u4e49","text":""},{"location":"zh/how_to_guides/write_a_new_model/#1python","title":"1.\u76f4\u63a5\u4f7f\u7528python\u4ee3\u7801\u6765\u7f16\u5199\u7f51\u7edc","text":""},{"location":"zh/how_to_guides/write_a_new_model/#_3","title":"\u6a21\u5757\u5bfc\u5165","text":"<p>\u5bfc\u5165MindSpore\u6846\u67b6\u4e2d\u7684nn\u6a21\u5757\u548cops\u6a21\u5757\uff0c\u7528\u4e8e\u5b9a\u4e49\u795e\u7ecf\u7f51\u7edc\u7684\u7ec4\u4ef6\u548c\u64cd\u4f5c\u3002 <pre><code>import mindspore.nn as nn\nimport mindspore.ops.operations as ops\n</code></pre></p>"},{"location":"zh/how_to_guides/write_a_new_model/#_4","title":"\u521b\u5efa\u6a21\u578b","text":"<p>\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7ee7\u627f\u81eann.Cell\u7684\u6a21\u578b\u7c7bMyModel\u3002\u5728\u6784\u9020\u51fd\u6570__init__\u4e2d\uff0c\u5b9a\u4e49\u6a21\u578b\u7684\u5404\u4e2a\u7ec4\u4ef6\uff1a</p> <pre><code>class MyModel(nn.Cell):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        #conv1\u662f\u4e00\u4e2a2D\u5377\u79ef\u5c42\uff0c\u8f93\u5165\u901a\u9053\u6570\u4e3a3\uff0c\u8f93\u51fa\u901a\u9053\u6570\u4e3a16\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3x3\uff0c\u6b65\u957f\u4e3a1\uff0c\u586b\u5145\u4e3a1\u3002\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n        #relu\u662f\u4e00\u4e2aReLU\u6fc0\u6d3b\u51fd\u6570\u64cd\u4f5c\u3002\n        self.relu = ops.ReLU()\n        #axpool\u662f\u4e00\u4e2a2D\u6700\u5927\u6c60\u5316\u5c42\uff0c\u6c60\u5316\u7a97\u53e3\u5927\u5c0f\u4e3a2x2\uff0c\u6b65\u957f\u4e3a2\u3002\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        #conv2\u662f\u53e6\u4e00\u4e2a2D\u5377\u79ef\u5c42\uff0c\u8f93\u5165\u901a\u9053\u6570\u4e3a16\uff0c\u8f93\u51fa\u901a\u9053\u6570\u4e3a32\uff0c\u5377\u79ef\u6838\u5927\u5c0f\u4e3a3x3\uff0c\u6b65\u957f\u4e3a1\uff0c\u586b\u5145\u4e3a1\u3002\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        #fc\u662f\u4e00\u4e2a\u5168\u8fde\u63a5\u5c42\uff0c\u8f93\u5165\u7279\u5f81\u7ef4\u5ea6\u4e3a32x8x8\uff0c\u8f93\u51fa\u7279\u5f81\u7ef4\u5ea6\u4e3a10\u3002\n        self.fc = nn.Dense(32 * 8 * 8, 10)\n\n    #\u5728construct\u65b9\u6cd5\u4e2d\uff0c\u5b9a\u4e49\u4e86\u6a21\u578b\u7684\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u3002\u8f93\u5165x\u7ecf\u8fc7\u5377\u79ef\u3001\u6fc0\u6d3b\u51fd\u6570\u3001\u6c60\u5316\u7b49\u64cd\u4f5c\u540e\uff0c\u901a\u8fc7\u5c55\u5e73\u64cd\u4f5c\u5c06\u7279\u5f81\u5f20\u91cf\u53d8\u4e3a\u4e00\u7ef4\u5411\u91cf\uff0c\u7136\u540e\u901a\u8fc7\u5168\u8fde\u63a5\u5c42\u5f97\u5230\u6700\u7ec8\u7684\u8f93\u51fa\u7ed3\u679c\u3002    \n    def construct(self, x): \n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = x.view(x.shape[0], -1)\n        x = self.fc(x)\n        return x\n</code></pre>"},{"location":"zh/how_to_guides/write_a_new_model/#_5","title":"\u521b\u5efa\u6a21\u578b\u5b9e\u4f8b","text":"<p>\u901a\u8fc7\u5b9e\u4f8b\u5316MyModel\u7c7b\uff0c\u521b\u5efa\u4e00\u4e2a\u6a21\u578b\u5b9e\u4f8bmodel\uff0c\u540e\u7eed\u53ef\u4ee5\u4f7f\u7528\u8be5\u5b9e\u4f8b\u8fdb\u884c\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u3002 <pre><code>model = MyModel()\n</code></pre></p>"},{"location":"zh/how_to_guides/write_a_new_model/#2yaml","title":"2.\u4f7f\u7528yaml\u6587\u4ef6\u7f16\u5199\u7f51\u7edc","text":"<p>\u901a\u5e38\u9700\u8981\u4ee5\u4e0b\u4e09\u4e2a\u6b65\u9aa4 - \u65b0\u5efa\u4e00\u4e2amymodel.yaml\u6587\u4ef6 - \u65b0\u5efa\u5bf9\u5e94\u7684mymodel.py\u6587\u4ef6  - \u5728mindyolo/models/init.py\u6587\u4ef6\u4e2d\u5f15\u5165\u8be5\u6a21\u578b</p> <p>\u4ee5\u4e0b\u662f\u7f16\u5199mymodel.yaml\u6587\u4ef6\u7684\u8be6\u7ec6\u6307\u5bfc: \u4ee5\u7f16\u5199\u4e00\u4e2a\u7b80\u5355\u7f51\u7edc\u4e3a\u4f8b\uff1a \u4ee5yaml\u683c\u5f0f\u7f16\u5199\u5fc5\u8981\u53c2\u6570\uff0c\u540e\u7eed\u5728mymodel.py\u6587\u4ef6\u91cc\u9762\u53ef\u4ee5\u7528\u5230\u8fd9\u4e9b\u53c2\u6570\u3002 \u5176\u4e2dnetwork\u90e8\u5206\u4e3a\u6a21\u578b\u7f51\u7edc  [[from, number, module, args], ...]\uff1a\u6bcf\u4e2a\u5143\u7d20\u4ee3\u8868\u4e00\u4e2a\u7f51\u7edc\u5c42\u7684\u914d\u7f6e\u3002 <pre><code># __BASE__\u4e2d\u7684yaml\u8868\u793a\u7528\u4e8e\u7ee7\u627f\u7684\u57fa\u7840\u914d\u7f6e\u6587\u4ef6\uff0c\u91cd\u590d\u7684\u53c2\u6570\u4f1a\u88ab\u5f53\u524d\u6587\u4ef6\u8986\u76d6\uff1b\n__BASE__:\n- '../coco.yaml'\n- './hyp.scratch-high.yaml'\n\nper_batch_size: 32\nimg_size: 640\nsync_bn: False\n\nnetwork:\nmodel_name: mymodel\ndepth_multiple: 1.0  # model depth multiple\nwidth_multiple: 1.0  # layer channel multiple\nstride: [ 8, 16, 32 ]\n\n# \u9aa8\u5e72\u7f51\u7edc\u90e8\u5206\u7684\u914d\u7f6e\uff0c\u6bcf\u5c42\u7684\u5143\u7d20\u542b\u4e49\u4e3a\n# [from, number, module, args]\n# \u4ee5\u7b2c\u4e00\u5c42\u4e3a\u4f8b\uff0c[-1, 1, ConvNormAct, [32, 3, 1]], \u8868\u793a\u8f93\u5165\u6765\u81ea `-1`(\u4e0a\u4e00\u5c42) \uff0c\u91cd\u590d\u6b21\u6570\u4e3a 1\uff0c\u6a21\u5757\u540d\u4e3a ConvNormAct\uff0c\u6a21\u5757\u8f93\u5165\u53c2\u6570\u4e3a [32, 3, 1]\uff1b\nbackbone: [[-1, 1, ConvNormAct, [32, 3, 1]],  # 0\n[-1, 1, ConvNormAct, [64, 3, 2]],  # 1-P1/2\n[-1, 1, Bottleneck, [64]],\n[-1, 1, ConvNormAct, [128, 3, 2]],  # 3-P2/4\n[-1, 2, Bottleneck, [128]],\n[-1, 1, ConvNormAct, [256, 3, 2]],  # 5-P3/8\n[-1, 8, Bottleneck, [256]],\n]\n\n#head\u90e8\u5206\u7684\u914d\u7f6e \nhead: [\n[ -1, 1, ConvNormAct, [ 512, 3, 2 ] ],  # 7-P4/16\n[ -1, 8, Bottleneck, [ 512 ] ],\n[ -1, 1, ConvNormAct, [ 1024, 3, 2 ] ],  # 9-P5/32\n[ -1, 4, Bottleneck, [ 1024 ] ],  # 10\n]\n</code></pre></p> <p>\u7f16\u5199mymodel.py\u6587\u4ef6:</p>"},{"location":"zh/how_to_guides/write_a_new_model/#_6","title":"\u6a21\u5757\u5bfc\u5165","text":"<p>\u9700\u8981\u5bfc\u5165\u5957\u4ef6\u5185\u7684\u6a21\u5757\u3002 \u5982<code>from .registry import register_model</code>\u7b49\u7b49</p> <pre><code>import numpy as np\n\nimport mindspore as ms\nfrom mindspore import Tensor, nn\n\n\nfrom .initializer import initialize_defult #\u7528\u4e8e\u521d\u59cb\u5316\u6a21\u578b\u7684\u9ed8\u8ba4\u53c2\u6570\uff0c\u5305\u62ec\u6743\u91cd\u521d\u59cb\u5316\u65b9\u5f0f\u3001BN \u5c42\u53c2\u6570\u7b49\u3002\nfrom .model_factory import build_model_from_cfg #\u7528\u4e8e\u6839\u636e YAML \u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u53c2\u6570\u6784\u5efa\u76ee\u6807\u68c0\u6d4b\u6a21\u578b\uff0c\u5e76\u8fd4\u56de\u8be5\u6a21\u578b\u7684\u5b9e\u4f8b\u3002\nfrom .registry import register_model #\u7528\u4e8e\u5c06\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\u6ce8\u518c\u5230 Mindyolo \u4e2d\uff0c\u4ee5\u4fbf\u5728 YAML \u914d\u7f6e\u6587\u4ef6\u4e2d\u4f7f\u7528\u3002\n\n#\u53ef\u89c1\u6027\u58f0\u660e\n__all__ = [\"MYmodel\", \"mymodel\"]\n</code></pre>"},{"location":"zh/how_to_guides/write_a_new_model/#_7","title":"\u521b\u5efa\u914d\u7f6e\u5b57\u5178","text":"<p>_cfg\u51fd\u6570\u662f\u4e00\u4e2a\u8f85\u52a9\u51fd\u6570\uff0c\u7528\u4e8e\u521b\u5efa\u914d\u7f6e\u5b57\u5178\u3002\u5b83\u63a5\u53d7\u4e00\u4e2aurl\u53c2\u6570\u548c\u5176\u4ed6\u5173\u952e\u5b57\u53c2\u6570\uff0c\u5e76\u8fd4\u56de\u4e00\u4e2a\u5305\u542burl\u548c\u5176\u4ed6\u53c2\u6570\u7684\u5b57\u5178\u3002 default_cfgs\u662f\u4e00\u4e2a\u5b57\u5178\uff0c\u7528\u4e8e\u5b58\u50a8\u9ed8\u8ba4\u914d\u7f6e\u3002\u5728\u8fd9\u91cc\uff0cmymodel\u4f5c\u4e3a\u952e\uff0c\u4f7f\u7528_cfg\u51fd\u6570\u521b\u5efa\u4e86\u4e00\u4e2a\u914d\u7f6e\u5b57\u5178\u3002 <pre><code>def _cfg(url=\"\", **kwargs):\n    return {\"url\": url, **kwargs}\n\ndefault_cfgs = {\"mymodel\": _cfg(url=\"\")}\n</code></pre></p>"},{"location":"zh/how_to_guides/write_a_new_model/#_8","title":"\u521b\u5efa\u6a21\u578b","text":"<p>\u5728<code>MindSpore</code>\u4e2d\uff0c\u6a21\u578b\u7684\u7c7b\u7ee7\u627f\u4e8e<code>nn.Cell</code>\uff0c\u4e00\u822c\u6765\u8bf4\u9700\u8981\u91cd\u8f7d\u4ee5\u4e0b\u4e24\u4e2a\u51fd\u6570\uff1a</p> <ul> <li>\u5728<code>__init__</code>\u51fd\u6570\u4e2d\uff0c\u5e94\u5f53\u5b9a\u4e49\u6a21\u578b\u4e2d\u9700\u8981\u7528\u5230\u7684module\u5c42\u3002</li> <li>\u5728<code>construct</code>\u51fd\u6570\u4e2d\u5b9a\u4e49\u6a21\u578b\u524d\u5411\u903b\u8f91\u3002 </li> </ul> <pre><code>class MYmodel(nn.Cell):\n\n    def __init__(self, cfg, in_channels=3, num_classes=None, sync_bn=False):\n        super(MYmodel, self).__init__()\n        self.cfg = cfg\n        self.stride = Tensor(np.array(cfg.stride), ms.int32)\n        self.stride_max = int(max(self.cfg.stride))\n        ch, nc = in_channels, num_classes\n\n        self.nc = nc  # override yaml value\n        self.model = build_model_from_cfg(model_cfg=cfg, in_channels=ch, num_classes=nc, sync_bn=sync_bn)\n        self.names = [str(i) for i in range(nc)]  # default names\n\n        initialize_defult()  # \u53ef\u9009\uff0c\u4f60\u53ef\u80fd\u9700\u8981initialize_defult\u65b9\u6cd5\u4ee5\u83b7\u5f97\u548cpytorch\u4e00\u6837\u7684conv2d\u3001dense\u5c42\u7684\u521d\u59cb\u5316\u65b9\u5f0f\uff1b\n\n    def construct(self, x):\n        return self.model(x)\n</code></pre>"},{"location":"zh/how_to_guides/write_a_new_model/#_9","title":"\u6ce8\u518c\u6a21\u578b\uff08\u53ef\u9009\uff09","text":"<p>\u5982\u679c\u9700\u8981\u4f7f\u7528mindyolo\u63a5\u53e3\u521d\u59cb\u5316\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u90a3\u4e48\u9700\u8981\u5148\u5bf9\u6a21\u578b\u8fdb\u884c**\u6ce8\u518c**\u548c**\u5bfc\u5165**</p> <p>\u6a21\u578b\u6ce8\u518c <pre><code>@register_model #\u6ce8\u518c\u540e\u7684\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7 create_model \u63a5\u53e3\u4ee5\u6a21\u578b\u540d\u7684\u65b9\u5f0f\u8fdb\u884c\u8bbf\u95ee\uff1b\ndef mymodel(cfg, in_channels=3, num_classes=None, **kwargs) -&gt; MYmodel:\n\"\"\"Get GoogLeNet model.\n    Refer to the base class `models.GoogLeNet` for more details.\"\"\"\n    model = MYmodel(cfg=cfg, in_channels=in_channels, num_classes=num_classes, **kwargs)\n    return model\n</code></pre> \u6a21\u578b\u5bfc\u5165 </p> <pre><code>#\u5728mindyolo/models/_init_.py\u6587\u4ef6\u4e2d\u6dfb\u52a0\u4ee5\u4e0b\u4ee3\u7801\n\nfrom . import mymodel #mymodel.py\u6587\u4ef6\u901a\u5e38\u653e\u5728mindyolo/models/\u76ee\u5f55\u4e0b\n__all__.extend(mymodel.__all__)\nfrom .mymodel import *\n</code></pre>"},{"location":"zh/how_to_guides/write_a_new_model/#main","title":"\u9a8c\u8bc1main","text":"<p>\u521d\u59cb\u7f16\u5199\u9636\u6bb5\u5e94\u5f53\u4fdd\u8bc1\u6a21\u578b\u662f\u53ef\u8fd0\u884c\u7684\u3002\u53ef\u901a\u8fc7\u4e0b\u8ff0\u4ee3\u7801\u5757\u8fdb\u884c\u57fa\u7840\u9a8c\u8bc1\uff1a \u9996\u5148\u5bfc\u5165\u6240\u9700\u7684\u6a21\u5757\u548c\u51fd\u6570\u3002\u7136\u540e\uff0c\u901a\u8fc7\u89e3\u6790\u914d\u7f6e\u5bf9\u8c61\u3002</p> <p><pre><code>if __name__ == \"__main__\":\n    from mindyolo.models.model_factory import create_model\n    from mindyolo.utils.config import parse_config\n\n    opt = parse_config()\n</code></pre> \u521b\u5efa\u6a21\u578b\u5e76\u6307\u5b9a\u76f8\u5173\u53c2\u6570\uff0c\u6ce8\u610f\uff1a\u5982\u679c\u8981\u5728create_model\u4e2d\u4f7f\u7528\u6587\u4ef6\u540d\u521b\u5efa\u81ea\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u90a3\u4e48\u9700\u8981\u5148\u4f7f\u7528\u6ce8\u518c\u5668@register_model\u8fdb\u884c\u6ce8\u518c\uff0c\u8bf7\u53c2\u89c1\u4e0a\u6587 \u6ce8\u518c\u6a21\u578b\uff08\u53ef\u9009)\u90e8\u5206\u5185\u5bb9 <pre><code>    model = create_model(\n        model_name=\"mymodel\",\n        model_cfg=opt.net,\n        num_classes=opt.data.nc,\n        sync_bn=opt.sync_bn if hasattr(opt, \"sync_bn\") else False,\n    ) \n</code></pre></p> <p>\u5426\u5219\uff0c\u8bf7\u4f7f\u7528import\u7684\u65b9\u5f0f\u5f15\u5165\u6a21\u578b</p> <p><pre><code>    from mindyolo.models.mymodel import MYmodel\n    model = MYmodel(\n        model_name=\"mymodel\",\n        model_cfg=opt.net,\n        num_classes=opt.data.nc,\n        sync_bn=opt.sync_bn if hasattr(opt, \"sync_bn\") else False,\n    ) \n</code></pre> \u6700\u540e\uff0c\u521b\u5efa\u4e00\u4e2a\u8f93\u5165\u5f20\u91cfx\u5e76\u5c06\u5176\u4f20\u9012\u7ed9\u6a21\u578b\u8fdb\u884c\u524d\u5411\u8ba1\u7b97\u3002 <pre><code>    x = Tensor(np.random.randn(1, 3, 640, 640), ms.float32)\n    out = model(x)\n    out = out[0] if isinstance(out, (list, tuple)) else out\n    print(f\"Output shape is {[o.shape for o in out]}\")\n</code></pre></p>"},{"location":"zh/notes/changelog/","title":"\u66f4\u65b0\u65e5\u5fd7","text":"<p>\u5373\u5c06\u5230\u6765</p>"},{"location":"zh/notes/code_of_conduct/","title":"\u884c\u4e3a\u51c6\u5219","text":"<p>\u5373\u5c06\u5230\u6765</p>"},{"location":"zh/notes/faq/","title":"\u5e38\u89c1\u95ee\u9898","text":"<p>\u5373\u5c06\u5230\u6765</p>"},{"location":"zh/tutorials/configuration/","title":"\u914d\u7f6e","text":""},{"location":"zh/tutorials/data_augmentation/#-","title":"\u6570\u636e\u589e\u5f3a--\u5de5\u5177\u7bb1\u81ea\u5e26","text":"<ul> <li>\u4ee5 configs/yolov7/hyp.scratch.tiny.yaml\u4e2d\u7684data.train_transforms\u4e3a\u4f8b.  \u5b83\u6307\u5b9a\u4e86\u4e00\u7ec4\u5e94\u7528\u4e8e\u56fe\u50cf\u6216\u6807\u7b7e\u7684\u6570\u636e\u589e\u5f3a\u64cd\u4f5c\uff0c\u7528\u4ee5\u751f\u6210\u4f5c\u4e3a\u6a21\u578b\u8f93\u5165\u6216\u635f\u5931\u51fd\u6570\u8f93\u5165\u7684\u6570\u636e\u3002\u8fd9\u4e9b\u6570\u636e\u589e\u5f3a\u51fd\u6570\u5b9a\u4e49\u5728 mindyolo/data/dataset.py \u4e2d\u3002 <pre><code>  train_transforms:\n- {func_name: mosaic, prob: 1.0, mosaic9_prob: 0.2, translate: 0.1, scale: 0.5}\n- {func_name: mixup, prob: 0.05, alpha: 8.0, beta: 8.0, needed_mosaic: True}\n- {func_name: hsv_augment, prob: 1.0, hgain: 0.015, sgain: 0.7, vgain: 0.4}\n- {func_name: pastein, prob: 0.05, num_sample: 30}\n- {func_name: label_norm, xyxy2xywh_: True}\n- {func_name: fliplr, prob: 0.5}\n- {func_name: label_pad, padding_size: 160, padding_value: -1}\n- {func_name: image_norm, scale: 255.}\n- {func_name: image_transpose, bgr2rgb: True, hwc2chw: True}\n</code></pre> \u6ce8\u610f\uff1afunc_name\u8868\u793a\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u540d\uff0cprob\u8868\u793a\u8be5\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u7684\u6267\u884c\u6982\u7387\uff0c\u9ed8\u8ba4\u503c\u4e3a1</li> </ul> <p>\u4e0a\u8ff0yaml\u6587\u4ef6\u6267\u884c\u7684\u5177\u4f53\u64cd\u4f5c\u5982\u4e0b\uff1a</p> <ul> <li> <p><code>mosaic</code>\uff1a\u4ee51.0\u7684\u6982\u7387\u5bf9\u8f93\u5165\u7684\u56fe\u7247\u8fdb\u884cmosaic\u64cd\u4f5c\uff0c\u5373\u5c064\u5f20\u4e0d\u540c\u7684\u56fe\u7247\u62fc\u63a5\u6210\u4e00\u5f20\u56fe\u7247\u3002mosaic9_prob\u8868\u793a\u4f7f\u75289\u5bab\u683c\u65b9\u5f0f\u8fdb\u884c\u62fc\u63a5\u7684\u6982\u7387\uff0ctranslate\u548cscale\u5206\u522b\u8868\u793a\u968f\u673a\u5e73\u79fb\u548c\u7f29\u653e\u7684\u7a0b\u5ea6\u3002</p> </li> <li> <p><code>mixup</code>\uff1a\u4ee50.05\u7684\u6982\u7387\u5bf9\u8f93\u5165\u7684\u56fe\u7247\u8fdb\u884cmixup\u64cd\u4f5c\uff0c\u5373\u5c06\u4e24\u5f20\u4e0d\u540c\u7684\u56fe\u7247\u8fdb\u884c\u6df7\u5408\u3002\u5176\u4e2dalpha\u548cbeta\u8868\u793a\u6df7\u5408\u7cfb\u6570\uff0cneeded_mosaic\u8868\u793a\u662f\u5426\u9700\u8981\u4f7f\u7528mosaic\u8fdb\u884c\u6df7\u5408\u3002</p> </li> <li> <p><code>hsv_augment</code>: HSV\u589e\u5f3a, \u4ee51.0\u7684\u6982\u7387\u5bf9\u8f93\u5165\u7684\u56fe\u7247\u8fdb\u884cHSV\u989c\u8272\u7a7a\u95f4\u7684\u8c03\u6574\uff0c\u589e\u52a0\u6570\u636e\u591a\u6837\u6027\u3002\u5176\u4e2dhgain\u3001sgain\u548cvgain\u5206\u522b\u8868\u793a\u5bf9H\u3001S\u3001V\u901a\u9053\u7684\u8c03\u6574\u7a0b\u5ea6\u3002</p> </li> <li> <p><code>pastein</code>\uff1a\u4ee50.05\u7684\u6982\u7387\u5728\u8f93\u5165\u7684\u56fe\u7247\u4e2d\u968f\u673a\u8d34\u5165\u4e00\u4e9b\u6837\u672c\u3002\u5176\u4e2dnum_sample\u8868\u793a\u968f\u673a\u8d34\u5165\u7684\u6837\u672c\u6570\u91cf\u3002</p> </li> <li> <p><code>label_norm</code>\uff1a\u5c06\u8f93\u5165\u7684\u6807\u7b7e\u4ece(x1, y1, x2, y2)\u7684\u683c\u5f0f\u8f6c\u6362\u4e3a(x, y, w, h)\u7684\u683c\u5f0f\u3002</p> </li> <li> <p><code>fliplr</code>\uff1a\u4ee50.5\u7684\u6982\u7387\u5bf9\u8f93\u5165\u7684\u56fe\u7247\u8fdb\u884c\u6c34\u5e73\u7ffb\u8f6c\uff0c\u589e\u52a0\u6570\u636e\u591a\u6837\u6027\u3002</p> </li> <li> <p><code>label_pad</code>\uff1a\u5bf9\u8f93\u5165\u7684\u6807\u7b7e\u8fdb\u884c\u586b\u5145\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u56fe\u7247\u90fd\u6709\u76f8\u540c\u6570\u91cf\u7684\u6807\u7b7e\u3002padding_size\u8868\u793a\u586b\u5145\u540e\u6807\u7b7e\u7684\u6570\u91cf\uff0cpadding_value\u8868\u793a\u586b\u5145\u7684\u503c\u3002</p> </li> <li> <p><code>image_norm</code>\uff1a\u5c06\u8f93\u5165\u7684\u56fe\u7247\u50cf\u7d20\u503c\u4ece[0, 255]\u8303\u56f4\u5185\u7f29\u653e\u5230[0, 1]\u8303\u56f4\u5185\u3002</p> </li> <li> <p><code>image_transpose</code>\uff1a\u5c06\u8f93\u5165\u7684\u56fe\u7247\u4eceBGR\u683c\u5f0f\u8f6c\u6362\u4e3aRGB\u683c\u5f0f\uff0c\u5e76\u5c06\u56fe\u7247\u7684\u901a\u9053\u6570\u4eceHWC\u683c\u5f0f\u8f6c\u6362\u4e3aCHW\u683c\u5f0f\u3002</p> </li> </ul> <p>\u5bf9\u4e8e\u6d4b\u8bd5\u6570\u636e\u589e\u5f3a\u51fd\u6570</p> <p><pre><code>  test_transforms:\n- {func_name: letterbox, scaleup: False}\n- {func_name: label_norm, xyxy2xywh_: True}\n- {func_name: label_pad, padding_size: 160, padding_value: -1}\n- {func_name: image_norm, scale: 255. }\n- {func_name: image_transpose, bgr2rgb: True, hwc2chw: True }\n</code></pre> - <code>letterbox</code>:\u5c06\u56fe\u7247\u6309\u7167\u7b49\u6bd4\u4f8b\u7f29\u653e\u540e\uff0c\u7528\u56fa\u5b9a\u7684\u80cc\u666f\u8272\u586b\u5145\u5230\u6307\u5b9a\u5927\u5c0f\u3002\u5176\u4e2dscaleup\u8868\u793a\u662f\u5426\u5141\u8bb8\u5c06\u56fe\u7247\u653e\u5927\uff0c\u4ee5\u9002\u5e94\u6307\u5b9a\u7684\u5927\u5c0f\u3002</p> <ul> <li> <p><code>label_norm</code>:\u6807\u7b7e\u5f52\u4e00\u5316,\u5c06\u8f93\u5165\u7684\u6807\u7b7e\u4ece(x1, y1, x2, y2)\u7684\u683c\u5f0f\u8f6c\u6362\u4e3a(x, y, w, h)\u7684\u683c\u5f0f\u3002</p> </li> <li> <p><code>label_pad</code>:\u6807\u7b7e\u586b\u5145,\u5bf9\u8f93\u5165\u7684\u6807\u7b7e\u8fdb\u884c\u586b\u5145\uff0c\u4f7f\u5f97\u6bcf\u4e2a\u56fe\u7247\u90fd\u6709\u76f8\u540c\u6570\u91cf\u7684\u6807\u7b7e\u3002padding_size\u8868\u793a\u586b\u5145\u540e\u6807\u7b7e\u7684\u6570\u91cf\uff0cpadding_value\u8868\u793a\u586b\u5145\u7684\u503c\u3002</p> </li> <li> <p><code>image_norm</code>:\u56fe\u7247\u5f52\u4e00\u5316,\u5c06\u8f93\u5165\u7684\u56fe\u7247\u50cf\u7d20\u503c\u4ece[0, 255]\u8303\u56f4\u5185\u7f29\u653e\u5230[0, 1]\u8303\u56f4\u5185\u3002</p> </li> <li> <p><code>image_transpose</code>:\u56fe\u7247\u53d8\u6362,\u5c06\u8f93\u5165\u7684\u56fe\u7247\u4eceBGR\u683c\u5f0f\u8f6c\u6362\u4e3aRGB\u683c\u5f0f\uff0c\u5e76\u5c06\u56fe\u7247\u7684\u901a\u9053\u6570\u4eceHWC\u683c\u5f0f\u8f6c\u6362\u4e3aCHW\u683c\u5f0f\u3002</p> </li> </ul>"},{"location":"zh/tutorials/data_augmentation/#-_1","title":"\u6570\u636e\u589e\u5f3a--\u81ea\u5b9a\u4e49","text":"<p>\u7f16\u5199\u6307\u5357\uff1a</p> <ul> <li>\u5728mindyolo/data/dataset.py\u6587\u4ef6COCODataset\u7c7b\u4e2d\u6dfb\u52a0\u81ea\u5b9a\u4e49\u6570\u636e\u589e\u5f3a\u65b9\u6cd5   </li> <li>\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u7684\u8f93\u5165\u901a\u5e38\u5305\u542b\u56fe\u7247\u3001\u6807\u7b7e\u548c\u81ea\u5b9a\u4e49\u53c2\u6570\u3002  </li> <li>\u7f16\u5199\u51fd\u6570\u4f53\u5185\u5bb9\uff0c\u81ea\u5b9a\u4e49\u8f93\u51fa\uff0c\u5982\u4e0b <pre><code>#mindyolo/data/dataset.py\n    def augmentation_fn(self, image, labels,args):\n        ...\n        return image, labels\n</code></pre></li> </ul> <p>\u4f7f\u7528\u6307\u5357\uff1a</p> <ul> <li>\u5728\u6a21\u578b\u7684yaml\u6587\u4ef6\u4e2d\uff0c\u4ee5\u5b57\u5178\u7684\u5f62\u5f0f\u5b9a\u4e49\u6b64\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u8be6\u60c5\u8bf7\u53c2\u89c1\u672c\u6587\u4e0a\u8ff0\u6307\u5bfc\u3002</li> </ul>"},{"location":"zh/tutorials/deployment/","title":"\u90e8\u7f72","text":""},{"location":"zh/tutorials/finetune/","title":"\u5fae\u8c03","text":""},{"location":"zh/tutorials/modelarts/","title":"\u4e91\u4e0a\u542f\u52a8","text":""},{"location":"zh/tutorials/modelarts/#mindyolo","title":"MindYOLO \u4e91\u4e0a\u8bad\u7ec3\u5feb\u901f\u5165\u95e8","text":"<p>\u672c\u6587\u4e3b\u8981\u4ecb\u7ecdMindYOLO\u501f\u52a9OPENI\u542f\u667a\u5e73\u53f0\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002</p>"},{"location":"zh/tutorials/modelarts/#_2","title":"\u8fc1\u79fb\u5916\u90e8\u9879\u76ee","text":"<p>\u70b9\u51fb\u542f\u667a\u5e73\u53f0\u4e3b\u9875\u9762\u53f3\u4e0a\u89d2\u7684\u52a0\u53f7\uff0c\u4ece\u4e0b\u62c9\u83dc\u5355\u4e2d\u9009\u62e9\u8fc1\u79fb\u5916\u90e8\u9879\u76ee\uff0c\u5c06MindYOLO\u4ecegithub\u8fc1\u79fb\u81f3\u542f\u667a\u5e73\u53f0\u3002</p> <p>\u8f93\u5165MindYOLO\u7684URL\u5373\u53ef\u8fdb\u884c\u8fc1\u79fb\u3002</p>"},{"location":"zh/tutorials/modelarts/#_3","title":"\u51c6\u5907\u6570\u636e\u96c6","text":"<p>\u53ef\u4ee5\u4e0a\u4f20\u81ea\u5df1\u7684\u6570\u636e\u96c6\uff0c\u4e5f\u53ef\u4ee5\u5173\u8054\u5e73\u53f0\u5df2\u6709\u7684\u6570\u636e\u96c6\u3002</p> <p>\u4e0a\u4f20\u4e2a\u4eba\u6570\u636e\u96c6\u9700\u5c06\u53ef\u7528\u96c6\u7fa4\u9009\u62e9\u4e3aNPU.</p>"},{"location":"zh/tutorials/modelarts/#_4","title":"\u51c6\u5907\u9884\u8bad\u7ec3\u6a21\u578b(\u53ef\u9009)","text":"<p>\u5982\u9700\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\uff0c\u53ef\u5728\u6a21\u578b\u9009\u9879\u5361\u4e2d\u6dfb\u52a0\u3002</p> <p>\u5bfc\u5165\u672c\u5730\u6a21\u578b\u65f6\uff0c\u6a21\u578b\u6846\u67b6\u7eed\u4e3aMindSpore.</p>"},{"location":"zh/tutorials/modelarts/#_5","title":"\u65b0\u5efa\u8bad\u7ec3\u4efb\u52a1","text":"<p>\u5728\u4e91\u8111\u9009\u9879\u5361\u4e2d\u9009\u62e9\u8bad\u7ec3\u4efb\u52a1-&gt;\u65b0\u5efa\u8bad\u7ec3\u4efb\u52a1\u3002</p> <p>\u57fa\u672c\u4fe1\u606f\u4e2d\u7684\u8ba1\u7b97\u8d44\u6e90\u9009\u62e9\u4e3aAscend NPU.</p> <p>\u8bbe\u7f6e\u53c2\u6570\u5e76\u6dfb\u52a0\u8fd0\u884c\u53c2\u6570\u3002</p> <ul> <li>\u5982\u9700\u52a0\u8f7d\u9884\u8bad\u7ec3\u6743\u91cd\uff0c\u53ef\u5728\u9009\u62e9\u6a21\u578b\u4e2d\u9009\u62e9\u5df2\u4e0a\u4f20\u7684\u6a21\u578b\u6587\u4ef6\uff0c\u5e76\u5728\u8fd0\u884c\u53c2\u6570\u4e2d\u589e\u52a0ckpt_dir\u53c2\u6570\uff0c\u53c2\u6570\u503c\u4e3a/cache/*.ckpt\uff0c*\u4e3a\u5b9e\u9645\u7684\u6587\u4ef6\u540d</li> <li>AI\u5f15\u64ce\u4e2d\u9700\u9009\u62e9MindSpore-1.8.1-aarch64\uff0c\u542f\u52a8\u6587\u4ef6\u4e3atrain.py</li> <li>\u8fd0\u884c\u53c2\u6570\u9700\u6dfb\u52a0enable_modelarts\uff0c\u503c\u4e3aTrue</li> <li>\u8fd0\u884c\u53c2\u6570\u4e2d\u7531config\u53c2\u6570\u6307\u5b9a\u5177\u4f53\u7684\u6a21\u578b\u7b97\u6cd5\uff0c\u53c2\u6570\u503c\u524d\u7f00\u4e3a/home/work/user-job-dir/\u8fd0\u884c\u7248\u672c\u53f7\uff0c\u65b0\u5efa\u8bad\u7ec3\u4efb\u52a1\u7684\u8fd0\u884c\u7248\u672c\u53f7\u901a\u5e38\u4e3aV0001</li> </ul> <p>\u5728\u5206\u5e03\u5f0f\u8bad\u7ec3\u573a\u666f\u4e0b\uff0c\u9700\u5728\u89c4\u683c\u4e2d\u9009\u597d\u5361\u6570\uff0c\u5e76\u5728\u8fd0\u884c\u53c2\u6570\u4e2d\u589e\u52a0is_parallel\u53c2\u6570\uff0c\u503c\u4e3aTrue</p>"},{"location":"zh/tutorials/modelarts/#_6","title":"\u4fee\u6539\u5df2\u6709\u8bad\u7ec3\u4efb\u52a1","text":"<p>\u70b9\u51fb\u5df2\u6709\u8bad\u7ec3\u4efb\u52a1\u7684\u4fee\u6539\u6309\u94ae\uff0c\u53ef\u4ee5\u57fa\u4e8e\u5df2\u6709\u8bad\u7ec3\u4efb\u52a1\u8fdb\u884c\u53c2\u6570\u4fee\u6539\u5e76\u8fd0\u884c\u65b0\u7684\u8bad\u7ec3\u4efb\u52a1\u3002</p> <p>\u6ce8\u610f\uff1a\u8fd0\u884c\u7248\u672c\u53f7=\u6240\u57fa\u4e8e\u7248\u672c\u53f7+1</p>"},{"location":"zh/tutorials/modelarts/#_7","title":"\u72b6\u6001\u67e5\u770b","text":"<p>\u70b9\u51fb\u76f8\u5e94\u7684\u4efb\u52a1\u540d\u79f0\uff0c\u5373\u53ef\u67e5\u770b\u914d\u7f6e\u4fe1\u606f\u3001\u65e5\u5fd7\u3001\u8d44\u6e90\u5360\u7528\u60c5\u51b5\uff0c\u8fdb\u884c\u7ed3\u679c\u4e0b\u8f7d\u3002</p>"},{"location":"zh/tutorials/quick_start/#mindyolo","title":"MindYOLO \u5feb\u901f\u5165\u95e8","text":"<p>\u672c\u6587\u7b80\u8981\u4ecb\u7ecdMindYOLO\u4e2d\u5185\u7f6e\u7684\u547d\u4ee4\u884c\u5de5\u5177\u7684\u4f7f\u7528\u65b9\u6cd5\u3002</p>"},{"location":"zh/tutorials/quick_start/#_2","title":"\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u63a8\u7406","text":"<ol> <li>\u4ecemodel zoo\u4e2d\u9009\u62e9\u4e00\u4e2a\u6a21\u578b\u53ca\u5176\u914d\u7f6e\u6587\u4ef6\uff0c\u4f8b\u5982\uff0c <code>./configs/yolov7/yolov7.yaml</code>.</li> <li>\u4ecemodel zoo\u4e2d\u4e0b\u8f7d\u76f8\u5e94\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u6743\u91cd\u6587\u4ef6\u3002</li> <li>\u4f7f\u7528\u5185\u7f6e\u914d\u7f6e\u8fdb\u884c\u63a8\u7406\uff0c\u8bf7\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a</li> </ol> <pre><code># NPU (\u9ed8\u8ba4)\npython demo/predict.py --config ./configs/yolov7/yolov7.yaml --weight=/path_to_ckpt/WEIGHT.ckpt --image_path /path_to_image/IMAGE.jpg\n\n# GPU\npython demo/predict.py --config ./configs/yolov7/yolov7.yaml --weight=/path_to_ckpt/WEIGHT.ckpt --image_path /path_to_image/IMAGE.jpg --device_target=GPU\n</code></pre> <p>\u6709\u5173\u547d\u4ee4\u884c\u53c2\u6570\u7684\u8be6\u7ec6\u4fe1\u606f\uff0c\u8bf7\u53c2\u9605<code>demo/predict.py -h</code>\uff0c\u6216\u67e5\u770b\u5176\u6e90\u4ee3\u7801\u3002</p> <ul> <li>\u8981\u5728CPU\u4e0a\u8fd0\u884c\uff0c\u8bf7\u5c06device_target\u7684\u503c\u4fee\u6539\u4e3aCPU.</li> <li>\u7ed3\u679c\u5c06\u4fdd\u5b58\u5728<code>./detect_results</code>\u76ee\u5f55\u4e0b</li> </ul>"},{"location":"zh/tutorials/quick_start/#_3","title":"\u4f7f\u7528\u547d\u4ee4\u884c\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30","text":"<ul> <li>\u6309\u7167YOLO\u683c\u5f0f\u51c6\u5907\u60a8\u7684\u6570\u636e\u96c6\u3002\u5982\u679c\u4f7f\u7528COCO\u6570\u636e\u96c6\uff08YOLO\u683c\u5f0f\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u8bf7\u4eceyolov5\u6216darknet\u51c6\u5907\u6570\u636e\u96c6.</li> </ul> <pre><code>  coco/\n    {train,val}2017.txt\n    annotations/\n      instances_{train,val}2017.json\n    images/\n      {train,val}2017/\n          00000001.jpg\n          ...\n          # image files that are mentioned in the corresponding train/val2017.txt\n    labels/\n      {train,val}2017/\n          00000001.txt\n          ...\n          # label files that are mentioned in the corresponding train/val2017.txt\n</code></pre> <ul> <li>\u5728\u591a\u5361NPU/GPU\u4e0a\u8fdb\u884c\u5206\u5e03\u5f0f\u6a21\u578b\u8bad\u7ec3\uff0c\u4ee58\u5361\u4e3a\u4f8b:</li> </ul> <pre><code>mpirun --allow-run-as-root -n 8 python train.py --config ./configs/yolov7/yolov7.yaml  --is_parallel True\n</code></pre> <ul> <li>\u5728\u5355\u5361NPU/GPU/CPU\u4e0a\u8bad\u7ec3\u6a21\u578b\uff1a</li> </ul> <pre><code>python train.py --config ./configs/yolov7/yolov7.yaml </code></pre> <ul> <li>\u8bc4\u4f30\u6a21\u578b\u7684\u7cbe\u5ea6\uff1a</li> </ul> <p><pre><code>python test.py --config ./configs/yolov7/yolov7.yaml --weight /path_to_ckpt/WEIGHT.ckpt\n</code></pre> \u6ce8\u610f\uff1a\u9ed8\u8ba4\u8d85\u53c2\u4e3a8\u5361\u8bad\u7ec3\uff0c\u5355\u5361\u60c5\u51b5\u9700\u8c03\u6574\u90e8\u5206\u53c2\u6570\u3002 \u9ed8\u8ba4\u8bbe\u5907\u4e3aAscend\uff0c\u60a8\u53ef\u4ee5\u6307\u5b9a'device_target'\u7684\u503c\u4e3aAscend/GPU/CPU\u3002 * \u6709\u5173\u66f4\u591a\u9009\u9879\uff0c\u8bf7\u53c2\u9605 <code>train/test.py -h</code>. * \u5728\u4e91\u8111\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u8bf7\u5728\u8fd9\u91cc\u67e5\u770b</p>"},{"location":"zh/tutorials/quick_start/#_4","title":"\u90e8\u7f72","text":"<p>\u8bf7\u5728\u8fd9\u91cc\u67e5\u770b.</p>"},{"location":"zh/tutorials/quick_start/#mindyolo-api","title":"\u5728\u4ee3\u7801\u4e2d\u4f7f\u7528MindYOLO API","text":"<p>\u656c\u8bf7\u671f\u5f85</p>"},{"location":"zh/tutorials/train_process/","title":"\u6df1\u5ea6\u5b66\u4e60Train and Eval \u6d41\u7a0b\u89e3\u6790","text":"<p>\u5171\u6709\u4ee5\u4e0b8\u4e2a\u6b65\u9aa4: </p> <ul> <li>\u521b\u5efa\u7f51\u7edc\u548c\u521d\u59cb\u5316 </li> <li>\u521b\u5efaDataLoader </li> <li>\u521b\u5efa\u635f\u5931\u51fd\u6570 </li> <li>\u521b\u5efa\u4f18\u5316\u5668\uff0c\u5e76\u8bbe\u7f6e\u76f8\u5173\u53c2\u6570 </li> <li>\u521b\u5efaTrain Step\u51fd\u6570 </li> <li>\u521b\u5efa\u56de\u8c03\u51fd\u6570 </li> <li>\u521b\u5efaTest\u7cbe\u5ea6\u8ba1\u7b97\u51fd\u6570 </li> <li>\u521b\u5efaTrainer\u5bf9\u8c61\uff0c\u5e76\u8c03\u7528train\u65b9\u6cd5\u6765\u8bad\u7ec3\u6a21\u578b</li> </ul>"}]}